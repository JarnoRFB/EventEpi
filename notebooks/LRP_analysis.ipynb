{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import imp\n",
    "import keras.backend\n",
    "import keras.models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "import keras\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "from string import punctuation\n",
    "from keras.models import Model, load_model\n",
    "from keras import optimizers\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.tokenize import PunktSentenceTokenizer\n",
    "from matplotlib import cm, transforms\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import roc_curve, auc, confusion_matrix\n",
    "\n",
    "import innvestigate\n",
    "import innvestigate.applications\n",
    "from innvestigate.utils.tests.networks import base as network_base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we are going to build a text classifer, inspired by experiments in [Arras et al. (2017a)][arras] and [Arras et al. (2017b)][arras2]. In particular, we are going to classify the relevance of epidemiological texts, and apply explanation methods provided by iNNvestigate to analyze how words in each article influence the articles's relevance prediction.\n",
    "\n",
    "We apply various explanation methods implemented in iNNvestigate to explain decisions from a trained model. The figure below is explanations of a review that we expect to see: red indicates a high relevance score in favour of the prediction, while blue is the opposite.\n",
    "\n",
    "![][sample]\n",
    "\n",
    "[arras]: http://www.aclweb.org/anthology/W16-1601\n",
    "[arras2]: https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0181142\n",
    "[sample]: https://i.imgur.com/IRQL5oh.png"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(13353)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abbooda\\appdata\\local\\continuum\\anaconda3\\envs\\rki\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "wv = KeyedVectors.load(\"self_trained_200\", mmap=\"r\")\n",
    "vocabs = [i for i in wv.wv.vocab.keys()] \n",
    "total_vocabs = len(vocabs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 1534827 vocabs.\n"
     ]
    }
   ],
   "source": [
    "# Unknown vocabs are set to <UNK>.\n",
    "encoder = dict(zip(['<UNK>'] + vocabs, range(len(vocabs) +1)))\n",
    "decoder = dict(zip(encoder.values(), encoder.keys()))\n",
    "\n",
    "print('We have %d vocabs.' % len(encoder))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_embedding = wv.wv.vectors\n",
    "\n",
    "# Unknown vocabs will have embedding weights of zero.\n",
    "embedding = np.zeros((pretrained_embedding.shape[0]+1, pretrained_embedding.shape[1]))\n",
    "embedding[1:, :] = pretrained_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spiting Training, Testing, and Validation Set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPLIT_LABEL_MAPPING = {\n",
    "    'training' : 1,\n",
    "    'testing': 2,\n",
    "    'validation': 3\n",
    "}\n",
    "\n",
    "MAX_SEQ_LENGTH = 200 # Calculated from where 63 is the shortest found text: min(epi_df.tokenized.apply(len))\n",
    "EMBEDDING_DIM = embedding.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_texts = pd.read_csv(\"with_label.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_texts[\"extracted_text\"] = (epi_texts[\"extracted_text\"]\n",
    "                               .apply(lambda x: \n",
    "                                          re.sub(r\"([0-9a-zA-Z]+)\\.([A-Za-z]+\\s)\",\n",
    "                                                 r\"\\g<1>. \\g<2>\",\n",
    "                                                 x)\n",
    "                                      )\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sent_tokenizer = PunktSentenceTokenizer(\" \".join(epi_texts[\"extracted_text\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"sent_tokenizer.p\", \"rb\") as f:\n",
    "    sent_tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_texts['tokenized'] = (epi_texts[\"extracted_text\"]\n",
    "                          .apply(lambda x: sent_tokenizer.tokenize(x))\n",
    "                          .apply(lambda x: [word_tokenize(sentence) for sentence in x])\n",
    "                          .apply(lambda article: [token for sentence in article for token in sentence])\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_texts[\"tokenized\"] = (epi_texts[\"tokenized\"]\n",
    "                               .apply(lambda x: [i.lower() for i in x if i not in punctuation])\n",
    "                              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = np.split(epi_texts.sample(frac=1), [int(.6*len(epi_texts)), int(.8*len(epi_texts))], )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"splitset_label\"] = \"training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate[\"splitset_label\"] = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"splitset_label\"] = \"testing\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate[\"splitset_label\"] = \"validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "epi_df = pd.concat([train, test, validate])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>label</th>\n",
       "      <th>tokenized</th>\n",
       "      <th>splitset_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>ProMED-mail is a program of the International ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[promed-mail, is, a, program, of, the, interna...</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3090</th>\n",
       "      <td>[Ref: S Rasool et al (2017): First Report of _...</td>\n",
       "      <td>False</td>\n",
       "      <td>[ref, s, rasool, et, al, 2017, first, report, ...</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>433</th>\n",
       "      <td>ProMED-mail is a program of the International ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[promed-mail, is, a, program, of, the, interna...</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1156</th>\n",
       "      <td>ProMED-mail is a program of the International ...</td>\n",
       "      <td>False</td>\n",
       "      <td>[promed-mail, is, a, program, of, the, interna...</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>- Epidemiological situation 22 Jun 2018, DRC M...</td>\n",
       "      <td>False</td>\n",
       "      <td>[epidemiological, situation, 22, jun, 2018, dr...</td>\n",
       "      <td>training</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         extracted_text  label  \\\n",
       "2857  ProMED-mail is a program of the International ...  False   \n",
       "3090  [Ref: S Rasool et al (2017): First Report of _...  False   \n",
       "433   ProMED-mail is a program of the International ...  False   \n",
       "1156  ProMED-mail is a program of the International ...  False   \n",
       "1780  - Epidemiological situation 22 Jun 2018, DRC M...  False   \n",
       "\n",
       "                                              tokenized splitset_label  \n",
       "2857  [promed-mail, is, a, program, of, the, interna...       training  \n",
       "3090  [ref, s, rasool, et, al, 2017, first, report, ...       training  \n",
       "433   [promed-mail, is, a, program, of, the, interna...       training  \n",
       "1156  [promed-mail, is, a, program, of, the, interna...       training  \n",
       "1780  [epidemiological, situation, 22, jun, 2018, dr...       training  "
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epi_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABEL_IDX_TO_NAME = {\n",
    "    0: 'irrelevant',\n",
    "    1: 'relevant'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_own_dataset(data_set):\n",
    "    filtered_indices = epi_df[\"splitset_label\"] == data_set\n",
    "    data_set_of_epi_df = epi_df[filtered_indices]\n",
    "    \n",
    "    xd = np.zeros((len(data_set_of_epi_df), MAX_SEQ_LENGTH, EMBEDDING_DIM))\n",
    "    y = data_set_of_epi_df[\"label\"].values.astype(int)\n",
    "    \n",
    "    articles = []\n",
    "    for i, tokenized in enumerate(data_set_of_epi_df[\"tokenized\"].values):\n",
    "        tokenized = [token.lower() for token in tokenized]\n",
    "        article = []\n",
    "        for j, v in enumerate(tokenized[:MAX_SEQ_LENGTH]):\n",
    "            if v in encoder:\n",
    "                e_idx = encoder[v]\n",
    "            else:\n",
    "                e_idx = 0\n",
    "            \n",
    "            xd[i, j, :] = embedding[e_idx]\n",
    "            article.append(e_idx)\n",
    "        articles.append(article)\n",
    "    \n",
    "    return dict(x4d=np.expand_dims(xd, axis=1), \n",
    "                y=y,\n",
    "                encoded_articles=articles)\n",
    "\n",
    "DATASETS = dict()\n",
    "\n",
    "for data_set in ['training', 'testing', 'validation']:\n",
    "    DATASETS[data_set] = prepare_own_dataset(data_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find text with lowest amount of <UNK> tokens\n",
    "ideces_of_lowest = []\n",
    "length = 4\n",
    "while len(ideces_of_lowest) < 1:\n",
    "    for sample_idx in range(len(DATASETS['testing']['encoded_articles'])):\n",
    "        text = ' '.join(map(lambda x: decoder[x], DATASETS['training']['encoded_articles'][sample_idx]))\n",
    "        amount_of_unk = len(re.findall(r\"<UNK>\", text))\n",
    "        if amount_of_unk == length:\n",
    "            ideces_of_lowest.append(sample_idx)\n",
    "    length += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review(ID=646): date fri 5 oct 2018 source outbreak news today edited http <UNK> the los angeles county department of public health lac dph is reporting an endemic flea-borne typhus outbreak in downtown los angeles between july and september 2018 health officials identified 9 cases of flea-borne typhus the cases have a history of living or working in downtown los angeles and 6 of them have reported experiencing homelessness or living in interim housing facilities in the area all cases were hospitalized and no deaths have occurred flea-borne typhus is endemic in lac with cases detected each year in recent years the average number of cases reported to lac dph has doubled to nearly 60 cases per year however geographic clusters of the size occurring in downtown los angeles are unusual most cases occur in the summer and fall months in lac the primary animals known to carry infected fleas include rats feral cats and opossums people with significant exposure to these animals are at risk of acquiring flea-borne typhus pet dogs and cats that are allowed outside may also come in contact with infected fleas and could carry them to humans infected animals are not known to get sick from flea-borne\n"
     ]
    }
   ],
   "source": [
    "print('Review(ID=%d): %s' %\n",
    "      (sample_idx, ' '.join(map(lambda x: decoder[x], DATASETS['training']['encoded_articles'][590]))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Construction\n",
    "\n",
    "Our classifier is a convolutional neural network, which was inspired by the network used in https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0181142"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_network(input_shape, output_n, activation=None, dense_unit=256, dropout_rate=0.25):\n",
    "    if activation:\n",
    "        activation = \"relu\"\n",
    "\n",
    "    net = {}\n",
    "    net[\"in\"] = network_base.input_layer(shape=input_shape)\n",
    "    \n",
    "    net[\"conv\"] = keras.layers.Conv2D(filters=100, kernel_size=(1,2), \n",
    "                                      strides=(1, 1),\n",
    "                                      activation='relu', \n",
    "                                      padding='valid')(net[\"in\"])\n",
    "    net[\"dropout\"] = keras.layers.Dropout(dropout_rate)(net[\"conv\"])\n",
    "    net[\"pool\"] = keras.layers.MaxPooling2D(pool_size=(1, input_shape[2]-1), strides=(1,1))(net[\"dropout\"])\n",
    "    \n",
    "    net[\"out\"] = network_base.dense_layer(keras.layers.Flatten()(net[\"pool\"]), units=output_n, activation=activation)\n",
    "    net[\"sm_out\"] = network_base.softmax(net[\"out\"])\n",
    "\n",
    "\n",
    "    net.update({\n",
    "        \"input_shape\": input_shape,\n",
    "\n",
    "        \"output_n\": output_n,\n",
    "    })\n",
    "    return net\n",
    "\n",
    "net = build_network((None, 1, MAX_SEQ_LENGTH, EMBEDDING_DIM), NUM_CLASSES)\n",
    "model_without_softmax, model_with_softmax = Model(inputs=net['in'], outputs=net['out']), Model(inputs=net['in'], outputs=net['sm_out'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_one_hot(y):\n",
    "    return keras.utils.to_categorical(y, NUM_CLASSES)\n",
    "\n",
    "def train_model(model,  batch_size=200, epochs=40):\n",
    "    \n",
    "    x_train = DATASETS['training']['x4d']\n",
    "    y_train = to_one_hot(DATASETS['training']['y'])\n",
    "    \n",
    "    x_test = DATASETS['testing']['x4d']\n",
    "    y_test = to_one_hot(DATASETS['testing']['y'])\n",
    "    \n",
    "    x_val = DATASETS['validation']['x4d']\n",
    "    y_val = to_one_hot(DATASETS['validation']['y'])\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  optimizer=optimizers.Adam(),\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    history = model.fit(x_train, y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=1,\n",
    "                        validation_data=(x_val, y_val),\n",
    "                        shuffle=True,\n",
    "                        class_weight=\"auto\"\n",
    "                       )\n",
    "    score = model.evaluate(x_test, y_test, verbose=0)\n",
    "    print('Test loss:', score[0])\n",
    "    print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1939 samples, validate on 646 samples\n",
      "Epoch 1/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0221 - acc: 0.9979 - val_loss: 0.2107 - val_acc: 0.9474\n",
      "Epoch 2/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0192 - acc: 0.9979 - val_loss: 0.2171 - val_acc: 0.9458\n",
      "Epoch 3/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0160 - acc: 0.9990 - val_loss: 0.2183 - val_acc: 0.9474\n",
      "Epoch 4/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0164 - acc: 0.9985 - val_loss: 0.2165 - val_acc: 0.9474\n",
      "Epoch 5/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0156 - acc: 0.9990 - val_loss: 0.2263 - val_acc: 0.9474\n",
      "Epoch 6/20\n",
      "1939/1939 [==============================] - 3s 2ms/step - loss: 0.0140 - acc: 0.9990 - val_loss: 0.2229 - val_acc: 0.9474\n",
      "Epoch 7/20\n",
      "1939/1939 [==============================] - 3s 2ms/step - loss: 0.0133 - acc: 0.9990 - val_loss: 0.2234 - val_acc: 0.9474\n",
      "Epoch 8/20\n",
      "1939/1939 [==============================] - 3s 2ms/step - loss: 0.0130 - acc: 0.9995 - val_loss: 0.2334 - val_acc: 0.9474\n",
      "Epoch 9/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0108 - acc: 0.9995 - val_loss: 0.2281 - val_acc: 0.9489\n",
      "Epoch 10/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0105 - acc: 0.9995 - val_loss: 0.2371 - val_acc: 0.9489\n",
      "Epoch 11/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0103 - acc: 0.9995 - val_loss: 0.2302 - val_acc: 0.9489\n",
      "Epoch 12/20\n",
      "1939/1939 [==============================] - 3s 2ms/step - loss: 0.0093 - acc: 0.9985 - val_loss: 0.2408 - val_acc: 0.9489\n",
      "Epoch 13/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0090 - acc: 0.9995 - val_loss: 0.2441 - val_acc: 0.9489\n",
      "Epoch 14/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0094 - acc: 0.9990 - val_loss: 0.2339 - val_acc: 0.9489\n",
      "Epoch 15/20\n",
      "1939/1939 [==============================] - 3s 2ms/step - loss: 0.0078 - acc: 0.9995 - val_loss: 0.2451 - val_acc: 0.9489\n",
      "Epoch 16/20\n",
      "1939/1939 [==============================] - 3s 2ms/step - loss: 0.0068 - acc: 0.9995 - val_loss: 0.2433 - val_acc: 0.9489\n",
      "Epoch 17/20\n",
      "1939/1939 [==============================] - 4s 2ms/step - loss: 0.0076 - acc: 0.9995 - val_loss: 0.2511 - val_acc: 0.9489\n",
      "Epoch 18/20\n",
      "1939/1939 [==============================] - 3s 2ms/step - loss: 0.0077 - acc: 0.9990 - val_loss: 0.2438 - val_acc: 0.9474\n",
      "Epoch 19/20\n",
      "1939/1939 [==============================] - 3s 2ms/step - loss: 0.0076 - acc: 0.9995 - val_loss: 0.2482 - val_acc: 0.9489\n",
      "Epoch 20/20\n",
      "1939/1939 [==============================] - 3s 2ms/step - loss: 0.0071 - acc: 0.9995 - val_loss: 0.2506 - val_acc: 0.9489\n",
      "Test loss: 0.18741113787633548\n",
      "Test accuracy: 0.955177743431221\n"
     ]
    }
   ],
   "source": [
    "train_model(model_with_softmax, batch_size=256, epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_without_softmax.set_weights(model_with_softmax.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_softmax.save(\"my_model_softmax\")\n",
    "model_without_softmax.save(\"my_model_without\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_with_softmax = load_model('my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = DATASETS['testing']['x4d']\n",
    "y_test = DATASETS['testing']['y']\n",
    "\n",
    "soft_max_predicted = model_with_softmax.predict(x_test)\n",
    "y_pred = [soft_max_predicted[i][1] for i in range(len(x_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, _ = roc_curve(y_test, arg_max_predicted)\n",
    "\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.plot(fpr, tpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_argmax = [soft_max_predicted[i].argmax() for i in range(len(x_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_argmax))\n",
    "print(confusion_matrix(y_test, y_argmax))\n",
    "print('AUC score: {:3f}'.format(auc(fpr, tpr)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Analysis and Visualization\n",
    "\n",
    "At this stage, we have a trained model and are ready to explain it via **iNNvestigate**'s analyzers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify methods that you would like to use to explain the model. \n",
    "# Please refer to iNNvestigate's documents for available methods.\n",
    "methods = ['gradient', 'lrp.z', 'lrp.alpha_2_beta_1', 'pattern.attribution']\n",
    "kwargs = [{}, {}, {}, {'pattern_type': 'relu'}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\abbooda\\appdata\\local\\continuum\\anaconda3\\envs\\rki\\lib\\site-packages\\innvestigate\\analyzer\\base.py:130: RuntimeWarning: This analyzer does not need to be trained. Still fit() is called.\n",
      "  \" Still fit() is called.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "8/8 [==============================] - 8s 1s/step - loss: 2.0000 - broadcast_1_loss: 1.0000 - broadcast_2_loss: 1.0000\n"
     ]
    }
   ],
   "source": [
    "# build an analyzer for each method\n",
    "analyzers = []\n",
    "\n",
    "for method, kws in zip(methods, kwargs):\n",
    "    analyzer = innvestigate.create_analyzer(method, model_without_softmax, **kws)\n",
    "    analyzer.fit(DATASETS['training']['x4d'], batch_size=256, verbose=1)\n",
    "    analyzers.append(analyzer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review 6 (1.8100s)\n",
      "Review 74 (0.0150s)\n",
      "Review 79 (0.0110s)\n",
      "Review 106 (0.0100s)\n",
      "Review 113 (0.0120s)\n",
      "Review 142 (0.0140s)\n",
      "Review 185 (0.0090s)\n",
      "Review 219 (0.0120s)\n",
      "Review 252 (0.0100s)\n",
      "Review 270 (0.0090s)\n",
      "Review 276 (0.0100s)\n",
      "Review 296 (0.0100s)\n",
      "Review 299 (0.0100s)\n",
      "Review 304 (0.0120s)\n",
      "Review 386 (0.0100s)\n",
      "Review 389 (0.0100s)\n",
      "Review 391 (0.0100s)\n",
      "Review 398 (0.0080s)\n",
      "Review 422 (0.0100s)\n",
      "Review 423 (0.0110s)\n",
      "Review 424 (0.0090s)\n",
      "Review 479 (0.0110s)\n",
      "Review 482 (0.0090s)\n",
      "Review 547 (0.0090s)\n",
      "Review 606 (0.0100s)\n",
      "Review 617 (0.0100s)\n",
      "Review 626 (0.0090s)\n",
      "Review 638 (0.0090s)\n"
     ]
    }
   ],
   "source": [
    "# specify indices of reviews that we want to investigate\n",
    "# test_sample_indices = [170, 321, 414]\n",
    "test_sample_indices = np.argwhere(DATASETS['testing']['y']==1).squeeze()\n",
    "test_sample_preds = [None]*len(test_sample_indices)\n",
    "\n",
    "# a variable to store analysis results.\n",
    "analysis = np.zeros([len(test_sample_indices), len(analyzers), 1, MAX_SEQ_LENGTH])\n",
    "\n",
    "for i, ridx in enumerate(test_sample_indices):\n",
    "\n",
    "    x, y = DATASETS['testing']['x4d'][ridx], DATASETS['testing']['y'][ridx]\n",
    "\n",
    "    t_start = time.time()\n",
    "    x = x.reshape((1, 1, MAX_SEQ_LENGTH, EMBEDDING_DIM))    \n",
    "\n",
    "    presm = model_without_softmax.predict_on_batch(x)[0] #forward pass without softmax\n",
    "    prob = model_with_softmax.predict_on_batch(x)[0] #forward pass with softmax\n",
    "    y_hat = prob.argmax()\n",
    "    test_sample_preds[i] = y_hat\n",
    "    \n",
    "    for aidx, analyzer in enumerate(analyzers):\n",
    "\n",
    "        a = np.squeeze(analyzer.analyze(x))\n",
    "        a = np.sum(a, axis=1)\n",
    "\n",
    "        analysis[i, aidx] = a\n",
    "    t_elapsed = time.time() - t_start\n",
    "    print('Review %d (%.4fs)'% (ridx, t_elapsed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "\n",
    "To this point, we have all analysis results from iNNvestigate's analyzers, and we are now ready to visualize them in a insightful way. We will use relevance scores from explanation methods to highlight the words in each review. \n",
    "\n",
    "We will use  the *blue-white-red (bwr)* color map for this purpose. Hence, words that have a positive score to the prediction are be shaded in *red*, while  negative-contribution or zero-contribution words are then highlighted in *blue*, and *white*, respectively.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a utility method visualizing the relevance scores of each word to the network's prediction. \n",
    "# one might skip understanding the function, and see its output first.\n",
    "def plot_text_heatmap(words, scores, title=\"\", width=10, height=0.2, verbose=0, max_word_per_line=20):\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    \n",
    "    ax = plt.gca()\n",
    "\n",
    "    ax.set_title(title, loc='left')\n",
    "    tokens = words\n",
    "    if verbose > 0:\n",
    "        print('len words : %d | len scores : %d' % (len(words), len(scores)))\n",
    "\n",
    "    cmap = plt.cm.ScalarMappable(cmap=cm.bwr)\n",
    "    cmap.set_clim(0, 1)\n",
    "    \n",
    "    canvas = ax.figure.canvas\n",
    "    t = ax.transData\n",
    "\n",
    "    normalized_scores = 0.5 * scores / np.max(np.abs(scores)) + 0.5\n",
    "    \n",
    "    if verbose > 1:\n",
    "        print('Raw score')\n",
    "        print(scores)\n",
    "        print('Normalized score')\n",
    "        print(normalized_scores)\n",
    "\n",
    "    # make sure the heatmap doesn't overlap with the title\n",
    "    loc_y = -0.2\n",
    "\n",
    "    for i, token in enumerate(tokens):\n",
    "        *rgb, _ = cmap.to_rgba(normalized_scores[i], bytes=True)\n",
    "        color = '#%02x%02x%02x' % tuple(rgb)\n",
    "        \n",
    "        text = ax.text(0.0, loc_y, token,\n",
    "                       bbox={\n",
    "                           'facecolor': color,\n",
    "                           'pad': 5.0,\n",
    "                           'linewidth': 0.5,\n",
    "                           'boxstyle': 'round,pad=0.5'\n",
    "                       }, transform=t)\n",
    "\n",
    "        text.draw(canvas.get_renderer())\n",
    "        ex = text.get_window_extent()\n",
    "        \n",
    "        # create a new line if the line exceeds the length\n",
    "        if (i+1) % max_word_per_line == 0:\n",
    "            loc_y = loc_y -  2.5\n",
    "            t = ax.transData\n",
    "        else:\n",
    "            t = transforms.offset_copy(text._transform, x=ex.width+15, units='dots')\n",
    "\n",
    "    if verbose == 0:\n",
    "        ax.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Traverse over the analysis results and visualize them.\n",
    "for i, idx in enumerate(test_sample_indices):\n",
    "\n",
    "    words = [decoder[t] for t in list(DATASETS['testing']['encoded_articles'][idx])]\n",
    "    \n",
    "    print('Review(id=%d): %s' % (idx, ' '.join(words)))\n",
    "    y_true = DATASETS['testing']['y'][idx]\n",
    "    y_pred = test_sample_preds[i]\n",
    "\n",
    "    print(\"Pred class : %s %s\" %\n",
    "          (LABEL_IDX_TO_NAME[y_pred], '✓' if y_pred == y_true else '✗ (%s)' % LABEL_IDX_TO_NAME[y_true])\n",
    "         )\n",
    "                                \n",
    "    for j, method in enumerate(methods):\n",
    "        plot_text_heatmap(words, analysis[i, j].reshape(-1), title='Method: %s' % method, verbose=0)\n",
    "        plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "673px",
    "left": "0px",
    "right": "1228px",
    "top": "110px",
    "width": "212px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
