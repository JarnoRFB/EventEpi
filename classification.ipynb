{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import inflect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nlp_surveillance.classifier import extract_sentence\n",
    "from nlp_surveillance.pipeline import ExtractSentencesAndLabel, RecommenderLabeling, RecommenderTierAnnotation\n",
    "from nlp_surveillance.classifier import summarize\n",
    "from utils.my_utils import split_list_and_distribute_to_new_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count/Date Classifier: Most Informative Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent = ExtractSentencesAndLabel('counts').data_output()\n",
    "df_sent['sentence']= df_sent['sentence'].apply(lambda x: list(set(x.split()) - set(stopwords.words('english'))))\n",
    "df_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent = split_list_and_distribute_to_new_rows(df_sent, 'sentence')\n",
    "df_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "as_tuples = df_sent.apply(tuple, axis=1).tolist()\n",
    "as_tuples = [({'word':word}, label) for label, word in as_tuples]\n",
    "as_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "clf = nltk.NaiveBayesClassifier.train(as_tuples)\n",
    "clf.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent_date = ExtractSentencesAndLabel('dates').data_output()\n",
    "df_sent_date['sentence']= df_sent_date['sentence'].apply(lambda x: list(set(x.split()) - set(stopwords.words('english'))))\n",
    "df_sent_date = split_list_and_distribute_to_new_rows(df_sent_date, 'sentence')\n",
    "as_tuples_date = df_sent_date.apply(tuple, axis=1).tolist()\n",
    "as_tuples_date = [({'sent':word}, label) for label, word in as_tuples_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_date = nltk.NaiveBayesClassifier.train(as_tuples_date)\n",
    "clf_date.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommand = RecommenderLabeling().data_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiers = RecommenderTierAnnotation().data_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = pd.concat([df_recommand, df_tiers],axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = df_clf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_clf['counts'] = df_clf['counts'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf['counts'] = df_clf['counts'].apply(np.nanmean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "engine = inflect.engine()\n",
    "df_clf['counts'] = (df_clf['counts']\n",
    "                    .apply(np.log10)\n",
    "                    .apply(lambda x: max(x, 0))\n",
    "                    .apply(lambda x: engine.number_to_words(int(x)))\n",
    "                   )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_clf['features'] = df_clf[['geoname', 'diseases', 'counts']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline_imb(TfidfVectorizer(),\n",
    "                         ADASYN(),\n",
    "                         MultinomialNB())\n",
    "pipe2 = make_pipeline_imb(TfidfVectorizer(),\n",
    "                         ADASYN(),\n",
    "                         MultinomialNB())\n",
    "pipe3 = make_pipeline_imb(TfidfVectorizer(),\n",
    "                         MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = to_train_d['counts'].replace(-np.inf, 0.).apply(int).apply(lambda x: p.number_to_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train_d['features'] = to_train_d['features'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = \\\n",
    "    ms.train_test_split(df['annotated'], df['label'], test_size=.2)\n",
    "y_balanced = compute_sample_weight(class_weight='balanced', y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe1.fit(X_train, y_train)\n",
    "# pipe2.fit(X_train, y_train)\n",
    "pipe3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_train))  #  TEXT WITHOUT STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  #  TEXT WITHOUT STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  #  TEXT WITHOUT STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  # RAW TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  # COMBINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  # DISEASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  # GEONAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  # COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_balanced = y_balanced/min(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_balanced = [int(np.ceil(i)) for i in y_balanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [int(np.ceil(i)) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_balanced)\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  #  weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = text.TfidfVectorizer()\n",
    "X = tf.fit_transform(to_train_d['geoname'])\n",
    "y = to_train_d['label'].apply(int)\n",
    "y_balanced = compute_sample_weight(class_weight='balanced', y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 100 * X.nnz / float(X.shape[0] * X.shape[1])\n",
    "print(f\"Each sample has ~{p:.2f}% non-zero features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = \\\n",
    "    ms.train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = ms.GridSearchCV(\n",
    "    nb.BernoulliNB(),\n",
    "    param_grid={'alpha': np.logspace(-2., 2., 50)})\n",
    "bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first get the words corresponding to each feature\n",
    "names = np.asarray(tf.get_feature_names())\n",
    "# Next, we display the 50 words with the largest\n",
    "# coefficients.\n",
    "print(','.join(names[np.argsort(\n",
    "    bnb.best_estimator_.coef_[0, :])[::-1][:50]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler, ADASYN\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._vocab, self._E = self._load_words()\n",
    "        \n",
    "    \n",
    "    def _load_words(self):\n",
    "        E = {}\n",
    "        vocab = []\n",
    "\n",
    "        with open('nlp_surveillance/glove.6B.50d.txt', 'r', encoding=\"utf8\") as file:\n",
    "            for i, line in enumerate(file):\n",
    "                l = line.split(' ')\n",
    "                if l[0].isalpha():\n",
    "                    v = [float(i) for i in l[1:]]\n",
    "                    E[l[0]] = np.array(v)\n",
    "                    vocab.append(l[0])\n",
    "        return np.array(vocab), E            \n",
    "\n",
    "    \n",
    "    def _get_word(self, v):\n",
    "        for i, emb in enumerate(self._E):\n",
    "            if np.array_equal(emb, v):\n",
    "                return self._vocab[i]\n",
    "        return None\n",
    "    \n",
    "    def _doc_mean(self, doc):\n",
    "        return np.mean(np.array([self._E[w.lower().strip()] for w in doc if w.lower().strip() in self._E]), axis=0)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([self._doc_mean(doc) for doc in X])\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(clf, X_test, y_test):\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred[:,1])\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    \n",
    "def print_scores(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    #print(classification.accuracy_score(y_pred.round(),y_test, normalize=True))\n",
    "    #print(confusion_matrix(y_pred,y_test))\n",
    "    #print('F1 score: {:3f}'.format(f1_score(y_test, y_pred)))\n",
    "    #print('AUC score: {:3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/recommender/with_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['extracted_text'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_transform(X, sample_size):\n",
    "    essays1 = X\n",
    "    tok_es1 = [word_tokenize(doc) for doc in essays1[:sample_size]]\n",
    "    met = MeanEmbeddingTransformer()\n",
    "    X_transform = met.fit_transform(tok_es1)\n",
    "    return X_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = tokenize_and_transform(X, 3200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('X_embed.csv', X_transform, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = np.loadtxt('X_embed.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_resample,\n",
    "#                                                     y_resample, stratify=y_resample, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transform,\n",
    "                                                    y[:3200], random_state=0)\n",
    "ada = ADASYN(random_state=0)\n",
    "X_resample, y_resample = ada.fit_sample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomOverSampler(random_state=0)\n",
    "X_resample, y_resample = rus.fit_sample(X_transform, y[:X_transform.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "print_scores(lr, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "print_scores(knn, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(knn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().fit(X_resample, y_resample)\n",
    "print_scores(rf, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC().fit(X_resample, y_resample)\n",
    "print_scores(svc, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC().fit(X_resample, y_resample)\n",
    "print_scores(svc, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier().fit(X_resample, y_resample)\n",
    "y_pred = dtc.predict(X_test)\n",
    "print_scores(dtc, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(dtc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mlp = MLPClassifier(max_iter=2000, early_stopping=True, se).fit(X_resample, y_resample)\n",
    "print_scores(mlp, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(mlp, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "mlp_r = MLPRegressor(max_iter=2000, early_stopping=True).fit(X_resample, y_resample)\n",
    "print_scores(mlp_r, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(mlp_r, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('mlp_clf.pkl', 'wb') as f:\n",
    "    pickle.dump(mlp, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(LogisticRegression(), \n",
    "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1]}, scoring=\"roc_auc\", cv=4)\n",
    "gs = gs.fit(X_resample, y_resample)\n",
    "print(gs.best_params_)\n",
    "print('best score: {:3f}'.format(gs.best_score_))\n",
    "plot_roc(gs, X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "gs = GridSearchCV(LinearSVC(), \n",
    "             param_grid=param_grid, scoring=\"roc_auc\", cv=4)\n",
    "gs = gs.fit(X_resample, y_resample)\n",
    "print(gs.best_params_)\n",
    "print('best score: {:3f}'.format(gs.best_score_))\n",
    "plot_roc(gs, X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'activation': ['relu', 'logistic', 'tanh'],\n",
    "              'alpha': [0.0001, 0.001, 0.01],\n",
    "              'learning_rate': ['constant', 'invscaling', 'adaptive'], 'tol': [0.01]}\n",
    "gs = GridSearchCV(MLPClassifier(), \n",
    "             param_grid=param_grid, scoring=\"roc_auc\", cv=4)\n",
    "gs = gs.fit(X_transform, y[:3200])\n",
    "print(gs.best_params_)\n",
    "print('best score: {:3f}'.format(gs.best_score_))\n",
    "plot_roc(gs, X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform_cluster = KMeans(n_clusters=5).fit_transform(X_transform, y[:3200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resample_cluster, y_resample_cluster = rus.fit_sample(X_transform_cluster, y[:X_transform_cluster.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cluster, X_test_cluster, y_train_cluster, y_test_cluster = train_test_split(X_resample_cluster,\n",
    "                                                    y_resample_cluster, stratify=y_resample_cluster, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "print_scores(lr, X_train_cluster, y_train_cluster, X_test_cluster, y_test_cluster)\n",
    "plot_roc(lr, X_test_cluster, y_test_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform_pca = PCA().fit_transform(X_transform, y[:3200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resample_pca, y_resample_pca = rus.fit_sample(X_transform_pca, y[:X_transform_pca.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cluster, X_test_cluster, y_train_cluster, y_test_cluster = train_test_split(X_resample_cluster,\n",
    "                                                    y_resample_cluster, stratify=y_resample_cluster, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "print_scores(lr, X_train_cluster, y_train_cluster, X_test_cluster, y_test_cluster)\n",
    "plot_roc(lr, X_test_cluster, y_test_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sne = 3200\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=10, n_iter=500)\n",
    "tsne_results = tsne.fit_transform(X_transform)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['x', 'y'])\n",
    "df_tsne['labels'] = y[:3200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "theme_set(theme_bw())\n",
    "(ggplot(df_tsne, aes(x='x', y='y', color='labels')) \n",
    " + geom_point()\n",
    " + xlab(\"t-SNE-x\") + ylab(\"t-SNE-y\") + ggtitle(\"doc embedding t-SNE\")\n",
    " + scale_color_manual(labels = (True, False), values = (\"pink\", \"purple\"))\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from web_app.app import summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "summarize('https://www.who.int/csr/don/04-march-2019-mers-oman/en/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
