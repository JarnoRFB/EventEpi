{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import inflect\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from nltk import sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn import model_selection\n",
    "from sklearn import naive_bayes\n",
    "from sklearn.utils.class_weight import compute_sample_weight\n",
    "\n",
    "from nlp_surveillance.classifier import extract_sentence\n",
    "from nlp_surveillance.pipeline import ExtractSentencesAndLabel, RecommenderLabeling, RecommenderTierAnnotation\n",
    "from nlp_surveillance.classifier import summarize\n",
    "from utils.my_utils import split_list_and_distribute_to_new_rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Count/Date Classifier: Most Informative Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Nigeria, response, Centre, 5577×Contact, +234...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Nigeria, response, Centre, 5577×Contact, +234...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Nigeria, response, Centre, 5577×Contact, +234...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[facilitiesSurvivors, United, event, Western, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[facilitiesSurvivors, United, event, Western, ...</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  label\n",
       "0  [Nigeria, response, Centre, 5577×Contact, +234...  False\n",
       "1  [Nigeria, response, Centre, 5577×Contact, +234...  False\n",
       "2  [Nigeria, response, Centre, 5577×Contact, +234...  False\n",
       "3  [facilitiesSurvivors, United, event, Western, ...  False\n",
       "4  [facilitiesSurvivors, United, event, Western, ...  False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent = ExtractSentencesAndLabel('counts').data_output()\n",
    "df_sent['sentence']= df_sent['sentence'].apply(lambda x: list(set(x.split()) - set(stopwords.words('english'))))\n",
    "df_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sentence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>Nigeria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>response</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>Centre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>5577×Contact</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>+234(0)809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label      sentence\n",
       "0  False       Nigeria\n",
       "1  False      response\n",
       "2  False        Centre\n",
       "3  False  5577×Contact\n",
       "4  False    +234(0)809"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sent = split_list_and_distribute_to_new_rows(df_sent, 'sentence')\n",
    "df_sent.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'word': 'Nigeria'}, False),\n",
       " ({'word': 'response'}, False),\n",
       " ({'word': 'Centre'}, False),\n",
       " ({'word': '5577×Contact'}, False),\n",
       " ({'word': '+234(0)809'}, False),\n",
       " ({'word': 'diseases.Connect'}, False),\n",
       " ({'word': 'epidemics'}, False),\n",
       " ({'word': '9700'}, False),\n",
       " ({'word': 'handlesToll'}, False),\n",
       " ({'word': 'year'}, False),\n",
       " ({'word': 'detection'}, False),\n",
       " ({'word': '711'}, False),\n",
       " ({'word': '2011'}, False),\n",
       " ({'word': 'challenges'}, False),\n",
       " ({'word': 'CentreToll'}, False),\n",
       " ({'word': '+234(0)708'}, False),\n",
       " ({'word': 'prevention,'}, False),\n",
       " ({'word': 'Disease'}, False),\n",
       " ({'word': 'NCDCThe'}, False),\n",
       " ({'word': 'emergencies'}, False),\n",
       " ({'word': 'non-communicable'}, False),\n",
       " ({'word': '(NCDC)'}, False),\n",
       " ({'word': 'health'}, False),\n",
       " ({'word': '955'}, False),\n",
       " ({'word': 'communicable'}, False),\n",
       " ({'word': '0010Whatsapp:'}, False),\n",
       " ({'word': 'Nigeria’s'}, False),\n",
       " ({'word': 'Subscribe'}, False),\n",
       " ({'word': 'Free'}, False),\n",
       " ({'word': '0800'}, False),\n",
       " ({'word': 'Number:'}, False),\n",
       " ({'word': 'established'}, False),\n",
       " ({'word': '0839SMS'}, False),\n",
       " ({'word': 'us'}, False),\n",
       " ({'word': 'control'}, False),\n",
       " ({'word': 'public'}, False),\n",
       " ({'word': 'Control'}, False),\n",
       " ({'word': 'preparedness'}, False),\n",
       " ({'word': 'NewsletterMandate'}, False),\n",
       " ({'word': 'enhance'}, False),\n",
       " ({'word': 'Nigeria'}, False),\n",
       " ({'word': 'response'}, False),\n",
       " ({'word': 'Centre'}, False),\n",
       " ({'word': '5577×Contact'}, False),\n",
       " ({'word': '+234(0)809'}, False),\n",
       " ({'word': 'diseases.Connect'}, False),\n",
       " ({'word': 'epidemics'}, False),\n",
       " ({'word': '9700'}, False),\n",
       " ({'word': 'handlesToll'}, False),\n",
       " ({'word': 'year'}, False),\n",
       " ({'word': 'detection'}, False),\n",
       " ({'word': '711'}, False),\n",
       " ({'word': '2011'}, False),\n",
       " ({'word': 'challenges'}, False),\n",
       " ({'word': 'CentreToll'}, False),\n",
       " ({'word': '+234(0)708'}, False),\n",
       " ({'word': 'prevention,'}, False),\n",
       " ({'word': 'Disease'}, False),\n",
       " ({'word': 'NCDCThe'}, False),\n",
       " ({'word': 'emergencies'}, False),\n",
       " ({'word': 'non-communicable'}, False),\n",
       " ({'word': '(NCDC)'}, False),\n",
       " ({'word': 'health'}, False),\n",
       " ({'word': '955'}, False),\n",
       " ({'word': 'communicable'}, False),\n",
       " ({'word': '0010Whatsapp:'}, False),\n",
       " ({'word': 'Nigeria’s'}, False),\n",
       " ({'word': 'Subscribe'}, False),\n",
       " ({'word': 'Free'}, False),\n",
       " ({'word': '0800'}, False),\n",
       " ({'word': 'Number:'}, False),\n",
       " ({'word': 'established'}, False),\n",
       " ({'word': '0839SMS'}, False),\n",
       " ({'word': 'us'}, False),\n",
       " ({'word': 'control'}, False),\n",
       " ({'word': 'public'}, False),\n",
       " ({'word': 'Control'}, False),\n",
       " ({'word': 'preparedness'}, False),\n",
       " ({'word': 'NewsletterMandate'}, False),\n",
       " ({'word': 'enhance'}, False),\n",
       " ({'word': 'Nigeria'}, False),\n",
       " ({'word': 'response'}, False),\n",
       " ({'word': 'Centre'}, False),\n",
       " ({'word': '5577×Contact'}, False),\n",
       " ({'word': '+234(0)809'}, False),\n",
       " ({'word': 'diseases.Connect'}, False),\n",
       " ({'word': 'epidemics'}, False),\n",
       " ({'word': '9700'}, False),\n",
       " ({'word': 'handlesToll'}, False),\n",
       " ({'word': 'year'}, False),\n",
       " ({'word': 'detection'}, False),\n",
       " ({'word': '711'}, False),\n",
       " ({'word': '2011'}, False),\n",
       " ({'word': 'challenges'}, False),\n",
       " ({'word': 'CentreToll'}, False),\n",
       " ({'word': '+234(0)708'}, False),\n",
       " ({'word': 'prevention,'}, False),\n",
       " ({'word': 'Disease'}, False),\n",
       " ({'word': 'NCDCThe'}, False),\n",
       " ({'word': 'emergencies'}, False),\n",
       " ({'word': 'non-communicable'}, False),\n",
       " ({'word': '(NCDC)'}, False),\n",
       " ({'word': 'health'}, False),\n",
       " ({'word': '955'}, False),\n",
       " ({'word': 'communicable'}, False),\n",
       " ({'word': '0010Whatsapp:'}, False),\n",
       " ({'word': 'Nigeria’s'}, False),\n",
       " ({'word': 'Subscribe'}, False),\n",
       " ({'word': 'Free'}, False),\n",
       " ({'word': '0800'}, False),\n",
       " ({'word': 'Number:'}, False),\n",
       " ({'word': 'established'}, False),\n",
       " ({'word': '0839SMS'}, False),\n",
       " ({'word': 'us'}, False),\n",
       " ({'word': 'control'}, False),\n",
       " ({'word': 'public'}, False),\n",
       " ({'word': 'Control'}, False),\n",
       " ({'word': 'preparedness'}, False),\n",
       " ({'word': 'NewsletterMandate'}, False),\n",
       " ({'word': 'enhance'}, False),\n",
       " ({'word': 'facilitiesSurvivors'}, False),\n",
       " ({'word': 'United'}, False),\n",
       " ({'word': 'event'}, False),\n",
       " ({'word': 'Western'}, False),\n",
       " ({'word': 'care'}, False),\n",
       " ({'word': '25'}, False),\n",
       " ({'word': 'achieve'}, False),\n",
       " ({'word': '2030.'}, False),\n",
       " ({'word': 'year'}, False),\n",
       " ({'word': 'Goals'}, False),\n",
       " ({'word': 'targets'}, False),\n",
       " ({'word': 'States'}, False),\n",
       " ({'word': '–'}, False),\n",
       " ({'word': 'goals'}, False),\n",
       " ({'word': 'Ebola'}, False),\n",
       " ({'word': 'Leonefield'}, False),\n",
       " ({'word': '17'}, False),\n",
       " ({'word': 'In'}, False),\n",
       " ({'word': 'Development'}, False),\n",
       " ({'word': 'the…MultimediaHand'}, False),\n",
       " ({'word': '191'}, False),\n",
       " ({'word': 'Abuja,'}, False),\n",
       " ({'word': 'held'}, False),\n",
       " ({'word': 'historic'}, False),\n",
       " ({'word': 'GoalsThe'}, False),\n",
       " ({'word': 'Nations'}, False),\n",
       " ({'word': 'hygiene'}, False),\n",
       " ({'word': 'agreed'}, False),\n",
       " ({'word': 'fight'}, False),\n",
       " ({'word': 'Sierra'}, False),\n",
       " ({'word': 'LimboStepping'}, False),\n",
       " ({'word': '(SDGs)'}, False),\n",
       " ({'word': 'LeoneSustainable'}, False),\n",
       " ({'word': 'Koinadugu,'}, False),\n",
       " ({'word': 'January'}, False),\n",
       " ({'word': '169'}, False),\n",
       " ({'word': 'Member'}, False),\n",
       " ({'word': 'Sustainable'}, False),\n",
       " ({'word': 'UN'}, False),\n",
       " ({'word': 'try'}, False),\n",
       " ({'word': 'report'}, False),\n",
       " ({'word': '2019'}, False),\n",
       " ({'word': 'facilitiesSurvivors'}, False),\n",
       " ({'word': 'United'}, False),\n",
       " ({'word': 'event'}, False),\n",
       " ({'word': 'Western'}, False),\n",
       " ({'word': 'care'}, False),\n",
       " ({'word': '25'}, False),\n",
       " ({'word': 'achieve'}, False),\n",
       " ({'word': '2030.'}, False),\n",
       " ({'word': 'year'}, False),\n",
       " ({'word': 'Goals'}, False),\n",
       " ({'word': 'targets'}, False),\n",
       " ({'word': 'States'}, False),\n",
       " ({'word': '–'}, False),\n",
       " ({'word': 'goals'}, False),\n",
       " ({'word': 'Ebola'}, False),\n",
       " ({'word': 'Leonefield'}, False),\n",
       " ({'word': '17'}, False),\n",
       " ({'word': 'In'}, False),\n",
       " ({'word': 'Development'}, False),\n",
       " ({'word': 'the…MultimediaHand'}, False),\n",
       " ({'word': '191'}, False),\n",
       " ({'word': 'Abuja,'}, False),\n",
       " ({'word': 'held'}, False),\n",
       " ({'word': 'historic'}, False),\n",
       " ({'word': 'GoalsThe'}, False),\n",
       " ({'word': 'Nations'}, False),\n",
       " ({'word': 'hygiene'}, False),\n",
       " ({'word': 'agreed'}, False),\n",
       " ({'word': 'fight'}, False),\n",
       " ({'word': 'Sierra'}, False),\n",
       " ({'word': 'LimboStepping'}, False),\n",
       " ({'word': '(SDGs)'}, False),\n",
       " ({'word': 'LeoneSustainable'}, False),\n",
       " ({'word': 'Koinadugu,'}, False),\n",
       " ({'word': 'January'}, False),\n",
       " ({'word': '169'}, False),\n",
       " ({'word': 'Member'}, False),\n",
       " ({'word': 'Sustainable'}, False),\n",
       " ({'word': 'UN'}, False),\n",
       " ({'word': 'try'}, False),\n",
       " ({'word': 'report'}, False),\n",
       " ({'word': '2019'}, False),\n",
       " ({'word': 'facilitiesSurvivors'}, False),\n",
       " ({'word': 'United'}, False),\n",
       " ({'word': 'event'}, False),\n",
       " ({'word': 'Western'}, False),\n",
       " ({'word': 'care'}, False),\n",
       " ({'word': '25'}, False),\n",
       " ({'word': 'achieve'}, False),\n",
       " ({'word': '2030.'}, False),\n",
       " ({'word': 'year'}, False),\n",
       " ({'word': 'Goals'}, False),\n",
       " ({'word': 'targets'}, False),\n",
       " ({'word': 'States'}, False),\n",
       " ({'word': '–'}, False),\n",
       " ({'word': 'goals'}, False),\n",
       " ({'word': 'Ebola'}, False),\n",
       " ({'word': 'Leonefield'}, False),\n",
       " ({'word': '17'}, False),\n",
       " ({'word': 'In'}, False),\n",
       " ({'word': 'Development'}, False),\n",
       " ({'word': 'the…MultimediaHand'}, False),\n",
       " ({'word': '191'}, False),\n",
       " ({'word': 'Abuja,'}, False),\n",
       " ({'word': 'held'}, False),\n",
       " ({'word': 'historic'}, False),\n",
       " ({'word': 'GoalsThe'}, False),\n",
       " ({'word': 'Nations'}, False),\n",
       " ({'word': 'hygiene'}, False),\n",
       " ({'word': 'agreed'}, False),\n",
       " ({'word': 'fight'}, False),\n",
       " ({'word': 'Sierra'}, False),\n",
       " ({'word': 'LimboStepping'}, False),\n",
       " ({'word': '(SDGs)'}, False),\n",
       " ({'word': 'LeoneSustainable'}, False),\n",
       " ({'word': 'Koinadugu,'}, False),\n",
       " ({'word': 'January'}, False),\n",
       " ({'word': '169'}, False),\n",
       " ({'word': 'Member'}, False),\n",
       " ({'word': 'Sustainable'}, False),\n",
       " ({'word': 'UN'}, False),\n",
       " ({'word': 'try'}, False),\n",
       " ({'word': 'report'}, False),\n",
       " ({'word': '2019'}, False),\n",
       " ({'word': 'retour'}, False),\n",
       " ({'word': 'confirmés.'}, False),\n",
       " ({'word': 'protéger'}, False),\n",
       " ({'word': 'et'}, False),\n",
       " ({'word': 'différents'}, False),\n",
       " ({'word': 'prévention'}, False),\n",
       " ({'word': 'actions'}, False),\n",
       " ({'word': 'son'}, False),\n",
       " ({'word': '2018,'}, False),\n",
       " ({'word': 'localisation'}, False),\n",
       " ({'word': 'sur'}, False),\n",
       " ({'word': 'l’ouest,'}, False),\n",
       " ({'word': 'ont'}, False),\n",
       " ({'word': 'Saint-Paul'}, False),\n",
       " ({'word': 'département,'}, False),\n",
       " ({'word': 'sont'}, False),\n",
       " ({'word': 'dans'}, False),\n",
       " ({'word': 'que'}, False),\n",
       " ({'word': 'Saint-Louis'}, False),\n",
       " ({'word': 'cas'}, False),\n",
       " ({'word': 'du'}, False),\n",
       " ({'word': 'de'}, False),\n",
       " ({'word': 'renforcent'}, False),\n",
       " ({'word': 'moustiques'}, False),\n",
       " ({'word': '6'}, False),\n",
       " ({'word': 'leurs'}, False),\n",
       " ({'word': '976'}, False),\n",
       " ({'word': 'qui'}, False),\n",
       " ({'word': 'sud,'}, False),\n",
       " ({'word': 'ainsi'}, False),\n",
       " ({'word': 'lutter'}, False),\n",
       " ({'word': 'se'}, False),\n",
       " ({'word': 'Possession.En'}, False),\n",
       " ({'word': 'dengue'}, False),\n",
       " ({'word': 'Avirons'}, False),\n",
       " ({'word': 'Les'}, False),\n",
       " ({'word': 'gestes'}, False),\n",
       " ({'word': 'janvier'}, False),\n",
       " ({'word': 'cette'}, False),\n",
       " ({'word': 'l’ensemble'}, False),\n",
       " ({'word': '1er'}, False),\n",
       " ({'word': 'semaine'}, False),\n",
       " ({'word': 'entourage.Depuis'}, False),\n",
       " ({'word': 'les'}, False),\n",
       " ({'word': 'à'}, False),\n",
       " ({'word': 'poursuit'}, False),\n",
       " ({'word': 'adopter'}, False),\n",
       " ({'word': 'Saint-Leu,'}, False),\n",
       " ({'word': 'niveau'}, False),\n",
       " ({'word': 'dispositifs'}, False),\n",
       " ({'word': 'été'}, False),\n",
       " ({'word': 'nombre'}, False),\n",
       " ({'word': 'L’augmentation'}, False),\n",
       " ({'word': 'vacances,'}, False),\n",
       " ({'word': 'rappeler'}, False),\n",
       " ({'word': 'notamment'}, False),\n",
       " ({'word': 'une'}, False),\n",
       " ({'word': 'au'}, False),\n",
       " ({'word': 'acteurs'}, False),\n",
       " ({'word': 'la'}, False),\n",
       " ({'word': 'chacun'}, False),\n",
       " ({'word': 'ce'}, False),\n",
       " ({'word': 'le'}, False),\n",
       " ({'word': 'multiplient'}, False),\n",
       " ({'word': 'pour'}, False),\n",
       " ({'word': 'avec'}, False),\n",
       " ({'word': 'contre'}, False),\n",
       " ({'word': 'retour'}, False),\n",
       " ({'word': 'confirmés.'}, False),\n",
       " ({'word': 'protéger'}, False),\n",
       " ({'word': 'et'}, False),\n",
       " ({'word': 'différents'}, False),\n",
       " ({'word': 'prévention'}, False),\n",
       " ({'word': 'actions'}, False),\n",
       " ({'word': 'son'}, False),\n",
       " ({'word': '2018,'}, False),\n",
       " ({'word': 'localisation'}, False),\n",
       " ({'word': 'sur'}, False),\n",
       " ({'word': 'l’ouest,'}, False),\n",
       " ({'word': 'ont'}, False),\n",
       " ({'word': 'Saint-Paul'}, False),\n",
       " ({'word': 'département,'}, False),\n",
       " ({'word': 'sont'}, False),\n",
       " ({'word': 'dans'}, False),\n",
       " ({'word': 'que'}, False),\n",
       " ({'word': 'Saint-Louis'}, False),\n",
       " ({'word': 'cas'}, False),\n",
       " ({'word': 'du'}, False),\n",
       " ({'word': 'de'}, False),\n",
       " ({'word': 'renforcent'}, False),\n",
       " ({'word': 'moustiques'}, False),\n",
       " ({'word': '6'}, False),\n",
       " ({'word': 'leurs'}, False),\n",
       " ({'word': '976'}, False),\n",
       " ({'word': 'qui'}, False),\n",
       " ({'word': 'sud,'}, False),\n",
       " ({'word': 'ainsi'}, False),\n",
       " ({'word': 'lutter'}, False),\n",
       " ({'word': 'se'}, False),\n",
       " ({'word': 'Possession.En'}, False),\n",
       " ({'word': 'dengue'}, False),\n",
       " ({'word': 'Avirons'}, False),\n",
       " ({'word': 'Les'}, False),\n",
       " ({'word': 'gestes'}, False),\n",
       " ({'word': 'janvier'}, False),\n",
       " ({'word': 'cette'}, False),\n",
       " ({'word': 'l’ensemble'}, False),\n",
       " ({'word': '1er'}, False),\n",
       " ({'word': 'semaine'}, False),\n",
       " ({'word': 'entourage.Depuis'}, False),\n",
       " ({'word': 'les'}, False),\n",
       " ({'word': 'à'}, False),\n",
       " ({'word': 'poursuit'}, False),\n",
       " ({'word': 'adopter'}, False),\n",
       " ({'word': 'Saint-Leu,'}, False),\n",
       " ({'word': 'niveau'}, False),\n",
       " ({'word': 'dispositifs'}, False),\n",
       " ({'word': 'été'}, False),\n",
       " ({'word': 'nombre'}, False),\n",
       " ({'word': 'L’augmentation'}, False),\n",
       " ({'word': 'vacances,'}, False),\n",
       " ({'word': 'rappeler'}, False),\n",
       " ({'word': 'notamment'}, False),\n",
       " ({'word': 'une'}, False),\n",
       " ({'word': 'au'}, False),\n",
       " ({'word': 'acteurs'}, False),\n",
       " ({'word': 'la'}, False),\n",
       " ({'word': 'chacun'}, False),\n",
       " ({'word': 'ce'}, False),\n",
       " ({'word': 'le'}, False),\n",
       " ({'word': 'multiplient'}, False),\n",
       " ({'word': 'pour'}, False),\n",
       " ({'word': 'avec'}, False),\n",
       " ({'word': 'contre'}, False),\n",
       " ({'word': 'follow-up'}, False),\n",
       " ({'word': 'deaths'}, False),\n",
       " ({'word': 'Bambari'}, False),\n",
       " ({'word': 'eight'}, False),\n",
       " ({'word': 'zero'}, False),\n",
       " ({'word': 'reported'}, False),\n",
       " ({'word': 'outbreak'}, False),\n",
       " ({'word': 'district'}, False),\n",
       " ({'word': 'Central'}, False),\n",
       " ({'word': ','}, False),\n",
       " ({'word': 'monkeypox'}, False),\n",
       " ({'word': 'Republic'}, False),\n",
       " ({'word': 'African'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': 'total'}, False),\n",
       " ({'word': '(CAR),'}, False),\n",
       " ({'word': 'In'}, False),\n",
       " ({'word': 'Mar.'}, False),\n",
       " ({'word': 'follow-up'}, False),\n",
       " ({'word': 'deaths'}, False),\n",
       " ({'word': 'Bambari'}, False),\n",
       " ({'word': 'eight'}, False),\n",
       " ({'word': 'zero'}, False),\n",
       " ({'word': 'reported'}, False),\n",
       " ({'word': 'outbreak'}, False),\n",
       " ({'word': 'district'}, False),\n",
       " ({'word': 'Central'}, False),\n",
       " ({'word': ','}, False),\n",
       " ({'word': 'monkeypox'}, False),\n",
       " ({'word': 'Republic'}, False),\n",
       " ({'word': 'African'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': 'total'}, False),\n",
       " ({'word': '(CAR),'}, False),\n",
       " ({'word': 'In'}, False),\n",
       " ({'word': 'Mar.'}, False),\n",
       " ({'word': 'Ministry'}, False),\n",
       " ({'word': 'declared'}, False),\n",
       " ({'word': 'outbreak.CAR'}, False),\n",
       " ({'word': 'since'}, False),\n",
       " ({'word': 'start'}, False),\n",
       " ({'word': '25'}, False),\n",
       " ({'word': 'Health'}, False),\n",
       " ({'word': 'outbreak'}, False),\n",
       " ({'word': 'Mar.'}, False),\n",
       " ({'word': 'age.'}, False),\n",
       " ({'word': 'Ippy.Four'}, False),\n",
       " ({'word': 'eight'}, False),\n",
       " ({'word': 'male;'}, False),\n",
       " ({'word': '5'}, False),\n",
       " ({'word': 'sub-district'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': '(50%)'}, False),\n",
       " ({'word': '17'}, False),\n",
       " ({'word': 'years'}, False),\n",
       " ({'word': 'age.'}, False),\n",
       " ({'word': 'Ippy.Four'}, False),\n",
       " ({'word': 'eight'}, False),\n",
       " ({'word': 'male;'}, False),\n",
       " ({'word': '5'}, False),\n",
       " ({'word': 'sub-district'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': '(50%)'}, False),\n",
       " ({'word': '17'}, False),\n",
       " ({'word': 'years'}, False),\n",
       " ({'word': 'age.'}, False),\n",
       " ({'word': 'Ippy.Four'}, False),\n",
       " ({'word': 'eight'}, False),\n",
       " ({'word': 'male;'}, False),\n",
       " ({'word': '5'}, False),\n",
       " ({'word': 'sub-district'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': '(50%)'}, False),\n",
       " ({'word': '17'}, False),\n",
       " ({'word': 'years'}, False),\n",
       " ({'word': 'age.'}, False),\n",
       " ({'word': 'Ippy.Four'}, False),\n",
       " ({'word': 'eight'}, False),\n",
       " ({'word': 'male;'}, False),\n",
       " ({'word': '5'}, False),\n",
       " ({'word': 'sub-district'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': '(50%)'}, False),\n",
       " ({'word': '17'}, False),\n",
       " ({'word': 'years'}, False),\n",
       " ({'word': 'three'}, False),\n",
       " ({'word': '2018,'}, False),\n",
       " ({'word': 'tested'}, False),\n",
       " ({'word': 'patients'}, False),\n",
       " ({'word': 'Institut'}, False),\n",
       " ({'word': 'Bangui.'}, False),\n",
       " ({'word': 'samples'}, False),\n",
       " ({'word': 'March'}, False),\n",
       " ({'word': 'Pasteur'}, False),\n",
       " ({'word': 'collected'}, False),\n",
       " ({'word': '25'}, False),\n",
       " ({'word': 'As'}, False),\n",
       " ({'word': 'hospitalized.Laboratory'}, False),\n",
       " ({'word': 'eight'}, False),\n",
       " ({'word': 'positive'}, False),\n",
       " ({'word': 'tested'}, False),\n",
       " ({'word': 'Six'}, False),\n",
       " ({'word': 'virus.'}, False),\n",
       " ({'word': 'monkeypox'}, False),\n",
       " ({'word': 'suspected'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': 'eight'}, False),\n",
       " ({'word': 'positive'}, False),\n",
       " ({'word': 'tested'}, False),\n",
       " ({'word': 'Six'}, False),\n",
       " ({'word': 'virus.'}, False),\n",
       " ({'word': 'monkeypox'}, False),\n",
       " ({'word': 'suspected'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': 'case'}, False),\n",
       " ({'word': 'developed'}, False),\n",
       " ({'word': 'One'}, False),\n",
       " ({'word': 'confirmation'}, False),\n",
       " ({'word': 'contact'}, False),\n",
       " ({'word': 'suspicious'}, False),\n",
       " ({'word': 'lesions'}, False),\n",
       " ({'word': 'self-limiting'}, False),\n",
       " ({'word': 'laboratory'}, False),\n",
       " ({'word': 'pending.Monkeypox'}, False),\n",
       " ({'word': 'disease'}, False),\n",
       " ({'word': 'largely'}, False),\n",
       " ({'word': 'i.e.'}, False),\n",
       " ({'word': 'case'}, False),\n",
       " ({'word': 'developed'}, False),\n",
       " ({'word': 'One'}, False),\n",
       " ({'word': 'confirmation'}, False),\n",
       " ({'word': 'contact'}, False),\n",
       " ({'word': 'suspicious'}, False),\n",
       " ({'word': 'lesions'}, False),\n",
       " ({'word': 'self-limiting'}, False),\n",
       " ({'word': 'laboratory'}, False),\n",
       " ({'word': 'pending.Monkeypox'}, False),\n",
       " ({'word': 'disease'}, False),\n",
       " ({'word': 'largely'}, False),\n",
       " ({'word': 'i.e.'}, False),\n",
       " ({'word': 'painful'}, False),\n",
       " ({'word': 'characteristic'}, False),\n",
       " ({'word': 'swelling'}, False),\n",
       " ({'word': 'vesicular'}, False),\n",
       " ({'word': 'fever,'}, False),\n",
       " ({'word': 'infection.'}, False),\n",
       " ({'word': 'jaw'}, False),\n",
       " ({'word': 'skin'}, False),\n",
       " ({'word': 'associated'}, False),\n",
       " ({'word': 'Generalized'}, False),\n",
       " ({'word': 'rashes,'}, False),\n",
       " ({'word': 'symptoms'}, False),\n",
       " ({'word': 'hospitalized,'}, False),\n",
       " ({'word': 'leaving'}, False),\n",
       " ({'word': 'veterinary'}, False),\n",
       " ({'word': 'people'}, False),\n",
       " ({'word': 'Anthrax'}, False),\n",
       " ({'word': 'Xinhua'}, False),\n",
       " ({'word': 'district'}, False),\n",
       " ({'word': 'anthrax.'}, False),\n",
       " ({'word': 'Nguma,'}, False),\n",
       " ({'word': 'northwestern'}, False),\n",
       " ({'word': 'official'}, False),\n",
       " ({'word': 'Ugandan'}, False),\n",
       " ({'word': 'others'}, False),\n",
       " ({'word': 'huaxia]KAMPALA,'}, False),\n",
       " ({'word': '6'}, False),\n",
       " ({'word': 'Arua,'}, False),\n",
       " ({'word': 'three'}, False),\n",
       " ({'word': 'positive'}, False),\n",
       " ({'word': '(Xinhua)'}, False),\n",
       " ({'word': 'Friday.Willy'}, False),\n",
       " ({'word': 'Arua'}, False),\n",
       " ({'word': '19:19:32[Editor:'}, False),\n",
       " ({'word': 'local'}, False),\n",
       " ({'word': '--'}, False),\n",
       " ({'word': 'person'}, False),\n",
       " ({'word': 'said'}, False),\n",
       " ({'word': 'blood'}, False),\n",
       " ({'word': 'UgandaSource:'}, False),\n",
       " ({'word': 'broken'}, False),\n",
       " ({'word': 'two'}, False),\n",
       " ({'word': 'killing'}, False),\n",
       " ({'word': 'tested'}, False),\n",
       " ({'word': 'district,'}, False),\n",
       " ({'word': 'refugee'}, False),\n",
       " ({'word': 'breaks'}, False),\n",
       " ({'word': 'told'}, False),\n",
       " ({'word': '2018-04-06'}, False),\n",
       " ({'word': 'April'}, False),\n",
       " ({'word': 'one'}, False),\n",
       " ({'word': 'taken'}, False),\n",
       " ({'word': 'samples'}, False),\n",
       " ({'word': 'camp'}, False),\n",
       " ({'word': 'officer'}, False),\n",
       " ({'word': 'settlement'}, False),\n",
       " ({'word': 'hospitalized,'}, False),\n",
       " ({'word': 'leaving'}, False),\n",
       " ({'word': 'veterinary'}, False),\n",
       " ({'word': 'people'}, False),\n",
       " ({'word': 'Anthrax'}, False),\n",
       " ({'word': 'Xinhua'}, False),\n",
       " ({'word': 'district'}, False),\n",
       " ({'word': 'anthrax.'}, False),\n",
       " ({'word': 'Nguma,'}, False),\n",
       " ({'word': 'northwestern'}, False),\n",
       " ({'word': 'official'}, False),\n",
       " ({'word': 'Ugandan'}, False),\n",
       " ({'word': 'others'}, False),\n",
       " ({'word': 'huaxia]KAMPALA,'}, False),\n",
       " ({'word': '6'}, False),\n",
       " ({'word': 'Arua,'}, False),\n",
       " ({'word': 'three'}, False),\n",
       " ({'word': 'positive'}, False),\n",
       " ({'word': '(Xinhua)'}, False),\n",
       " ({'word': 'Friday.Willy'}, False),\n",
       " ({'word': 'Arua'}, False),\n",
       " ({'word': '19:19:32[Editor:'}, False),\n",
       " ({'word': 'local'}, False),\n",
       " ({'word': '--'}, False),\n",
       " ({'word': 'person'}, False),\n",
       " ({'word': 'said'}, False),\n",
       " ({'word': 'blood'}, False),\n",
       " ({'word': 'UgandaSource:'}, False),\n",
       " ({'word': 'broken'}, False),\n",
       " ({'word': 'two'}, False),\n",
       " ({'word': 'killing'}, False),\n",
       " ({'word': 'tested'}, False),\n",
       " ({'word': 'district,'}, False),\n",
       " ({'word': 'refugee'}, False),\n",
       " ({'word': 'breaks'}, False),\n",
       " ({'word': 'told'}, False),\n",
       " ({'word': '2018-04-06'}, False),\n",
       " ({'word': 'April'}, False),\n",
       " ({'word': 'one'}, False),\n",
       " ({'word': 'taken'}, False),\n",
       " ({'word': 'samples'}, False),\n",
       " ({'word': 'camp'}, False),\n",
       " ({'word': 'officer'}, False),\n",
       " ({'word': 'settlement'}, False),\n",
       " ({'word': 'hospitalized,'}, False),\n",
       " ({'word': 'leaving'}, False),\n",
       " ({'word': 'veterinary'}, False),\n",
       " ({'word': 'people'}, False),\n",
       " ({'word': 'Anthrax'}, False),\n",
       " ({'word': 'Xinhua'}, False),\n",
       " ({'word': 'district'}, False),\n",
       " ({'word': 'anthrax.'}, False),\n",
       " ({'word': 'Nguma,'}, False),\n",
       " ({'word': 'northwestern'}, False),\n",
       " ({'word': 'official'}, False),\n",
       " ({'word': 'Ugandan'}, False),\n",
       " ({'word': 'others'}, False),\n",
       " ({'word': 'huaxia]KAMPALA,'}, False),\n",
       " ({'word': '6'}, False),\n",
       " ({'word': 'Arua,'}, False),\n",
       " ({'word': 'three'}, False),\n",
       " ({'word': 'positive'}, False),\n",
       " ({'word': '(Xinhua)'}, False),\n",
       " ({'word': 'Friday.Willy'}, False),\n",
       " ({'word': 'Arua'}, False),\n",
       " ({'word': '19:19:32[Editor:'}, False),\n",
       " ({'word': 'local'}, False),\n",
       " ({'word': '--'}, False),\n",
       " ({'word': 'person'}, False),\n",
       " ({'word': 'said'}, False),\n",
       " ({'word': 'blood'}, False),\n",
       " ({'word': 'UgandaSource:'}, False),\n",
       " ({'word': 'broken'}, False),\n",
       " ({'word': 'two'}, False),\n",
       " ({'word': 'killing'}, False),\n",
       " ({'word': 'tested'}, False),\n",
       " ({'word': 'district,'}, False),\n",
       " ({'word': 'refugee'}, False),\n",
       " ({'word': 'breaks'}, False),\n",
       " ({'word': 'told'}, False),\n",
       " ({'word': '2018-04-06'}, False),\n",
       " ({'word': 'April'}, False),\n",
       " ({'word': 'one'}, False),\n",
       " ({'word': 'taken'}, False),\n",
       " ({'word': 'samples'}, False),\n",
       " ({'word': 'camp'}, False),\n",
       " ({'word': 'officer'}, False),\n",
       " ({'word': 'settlement'}, False),\n",
       " ({'word': 'hospitalized,'}, True),\n",
       " ({'word': 'leaving'}, True),\n",
       " ({'word': 'veterinary'}, True),\n",
       " ({'word': 'people'}, True),\n",
       " ({'word': 'Anthrax'}, True),\n",
       " ({'word': 'Xinhua'}, True),\n",
       " ({'word': 'district'}, True),\n",
       " ({'word': 'anthrax.'}, True),\n",
       " ({'word': 'Nguma,'}, True),\n",
       " ({'word': 'northwestern'}, True),\n",
       " ({'word': 'official'}, True),\n",
       " ({'word': 'Ugandan'}, True),\n",
       " ({'word': 'others'}, True),\n",
       " ({'word': 'huaxia]KAMPALA,'}, True),\n",
       " ({'word': '6'}, True),\n",
       " ({'word': 'Arua,'}, True),\n",
       " ({'word': 'three'}, True),\n",
       " ({'word': 'positive'}, True),\n",
       " ({'word': '(Xinhua)'}, True),\n",
       " ({'word': 'Friday.Willy'}, True),\n",
       " ({'word': 'Arua'}, True),\n",
       " ({'word': '19:19:32[Editor:'}, True),\n",
       " ({'word': 'local'}, True),\n",
       " ({'word': '--'}, True),\n",
       " ({'word': 'person'}, True),\n",
       " ({'word': 'said'}, True),\n",
       " ({'word': 'blood'}, True),\n",
       " ({'word': 'UgandaSource:'}, True),\n",
       " ({'word': 'broken'}, True),\n",
       " ({'word': 'two'}, True),\n",
       " ({'word': 'killing'}, True),\n",
       " ({'word': 'tested'}, True),\n",
       " ({'word': 'district,'}, True),\n",
       " ({'word': 'refugee'}, True),\n",
       " ({'word': 'breaks'}, True),\n",
       " ({'word': 'told'}, True),\n",
       " ({'word': '2018-04-06'}, True),\n",
       " ({'word': 'April'}, True),\n",
       " ({'word': 'one'}, True),\n",
       " ({'word': 'taken'}, True),\n",
       " ({'word': 'samples'}, True),\n",
       " ({'word': 'camp'}, True),\n",
       " ({'word': 'officer'}, True),\n",
       " ({'word': 'settlement'}, True),\n",
       " ({'word': 'refugees'}, False),\n",
       " ({'word': 'live'}, False),\n",
       " ({'word': 'people'}, False),\n",
       " ({'word': '\"Two'}, False),\n",
       " ({'word': 'undergoing'}, False),\n",
       " ({'word': 'animals,\"'}, False),\n",
       " ({'word': 'risk'}, False),\n",
       " ({'word': 'many'}, False),\n",
       " ({'word': 'camp.'}, False),\n",
       " ({'word': 'disease'}, False),\n",
       " ({'word': 'sharing'}, False),\n",
       " ({'word': 'still'}, False),\n",
       " ({'word': 'deadly'}, False),\n",
       " ({'word': 'treatment'}, False),\n",
       " ({'word': 'fighting'}, False),\n",
       " ({'word': 'contracting'}, False),\n",
       " ({'word': 'said.South'}, False),\n",
       " ({'word': 'fled'}, False),\n",
       " ({'word': 'victims'}, False),\n",
       " ({'word': 'houses'}, False),\n",
       " ({'word': 'home'}, False),\n",
       " ({'word': 'Nguma'}, False),\n",
       " ({'word': 'Sudanese'}, False),\n",
       " ({'word': 'refugees'}, False),\n",
       " ({'word': 'dangerous,\"'}, False),\n",
       " ({'word': 'Anthrax'}, False),\n",
       " ({'word': 'animals,'}, False),\n",
       " ({'word': 'agencies'}, False),\n",
       " ({'word': 'reported'}, False),\n",
       " ({'word': 'humanitarian'}, False),\n",
       " ({'word': 'ignore'}, False),\n",
       " ({'word': '15'}, False),\n",
       " ({'word': 'result'}, False),\n",
       " ({'word': 'anus.More'}, False),\n",
       " ({'word': 'screen'}, False),\n",
       " ({'word': 'animals'}, False),\n",
       " ({'word': '\"The'}, False),\n",
       " ({'word': '2016.'}, False),\n",
       " ({'word': 'suspected'}, False),\n",
       " ({'word': 'challenge'}, False),\n",
       " ({'word': 'said.He'}, False),\n",
       " ({'word': 'beings'}, False),\n",
       " ({'word': 'blood'}, False),\n",
       " ({'word': 'farmers'}, False),\n",
       " ({'word': 'advised'}, False),\n",
       " ({'word': 'nostrils'}, False),\n",
       " ({'word': 'area'}, False),\n",
       " ({'word': 'signs'}, False),\n",
       " ({'word': 'death'}, False),\n",
       " ({'word': 'Uganda,'}, False),\n",
       " ({'word': 'human'}, False),\n",
       " ({'word': 'Uganda'}, False),\n",
       " ({'word': 'oozing'}, False),\n",
       " ({'word': 'anthrax,'}, False),\n",
       " ({'word': 'said.An'}, False),\n",
       " ({'word': 'outbreak'}, False),\n",
       " ({'word': 'last'}, False),\n",
       " ({'word': 'Nguma'}, False),\n",
       " ({'word': 'report'}, False),\n",
       " ({'word': 'cross'}, False),\n",
       " ({'word': 'died'}, False),\n",
       " ({'word': 'refugees'}, False),\n",
       " ({'word': 'dangerous,\"'}, False),\n",
       " ({'word': 'Anthrax'}, False),\n",
       " ({'word': 'animals,'}, False),\n",
       " ({'word': 'agencies'}, False),\n",
       " ({'word': 'reported'}, False),\n",
       " ({'word': 'humanitarian'}, False),\n",
       " ({'word': 'ignore'}, False),\n",
       " ({'word': '15'}, False),\n",
       " ({'word': 'result'}, False),\n",
       " ({'word': 'anus.More'}, False),\n",
       " ({'word': 'screen'}, False),\n",
       " ({'word': 'animals'}, False),\n",
       " ({'word': '\"The'}, False),\n",
       " ({'word': '2016.'}, False),\n",
       " ({'word': 'suspected'}, False),\n",
       " ({'word': 'challenge'}, False),\n",
       " ({'word': 'said.He'}, False),\n",
       " ({'word': 'beings'}, False),\n",
       " ({'word': 'blood'}, False),\n",
       " ({'word': 'farmers'}, False),\n",
       " ({'word': 'advised'}, False),\n",
       " ({'word': 'nostrils'}, False),\n",
       " ({'word': 'area'}, False),\n",
       " ({'word': 'signs'}, False),\n",
       " ({'word': 'death'}, False),\n",
       " ({'word': 'Uganda,'}, False),\n",
       " ({'word': 'human'}, False),\n",
       " ({'word': 'Uganda'}, False),\n",
       " ({'word': 'oozing'}, False),\n",
       " ({'word': 'anthrax,'}, False),\n",
       " ({'word': 'said.An'}, False),\n",
       " ({'word': 'outbreak'}, False),\n",
       " ({'word': 'last'}, False),\n",
       " ({'word': 'Nguma'}, False),\n",
       " ({'word': 'report'}, False),\n",
       " ({'word': 'cross'}, False),\n",
       " ({'word': 'died'}, False),\n",
       " ({'word': 'National'}, True),\n",
       " ({'word': '2018,'}, True),\n",
       " ({'word': 'Listeria'}, True),\n",
       " ({'word': 'listeriosis'}, True),\n",
       " ({'word': 'associated'}, True),\n",
       " ({'word': 'confirmed'}, True),\n",
       " ({'word': 'reported.'}, True),\n",
       " ({'word': '(NFP)'}, True),\n",
       " ({'word': '6'}, True),\n",
       " ({'word': 'news9'}, True),\n",
       " ({'word': '20'}, True),\n",
       " ({'word': 'March'}, True),\n",
       " ({'word': 'Australian'}, True),\n",
       " ({'word': '2'}, True),\n",
       " ({'word': 'Focal'}, True),\n",
       " ({'word': 'Disease'}, True),\n",
       " ({'word': '17'}, True),\n",
       " ({'word': '2018'}, True),\n",
       " ({'word': 'infection'}, True),\n",
       " ({'word': 'grower.From'}, True),\n",
       " ({'word': '1'}, True),\n",
       " ({'word': 'outbreak'}, True),\n",
       " ({'word': 'probable)'}, True),\n",
       " ({'word': '(cantaloupe)'}, True),\n",
       " ({'word': 'notified'}, True),\n",
       " ({'word': 'April'}, True),\n",
       " ({'word': '(listeriosis)'}, True),\n",
       " ({'word': 'consumption'}, True),\n",
       " ({'word': 'single'}, True),\n",
       " ({'word': 'Point'}, True),\n",
       " ({'word': '2018On'}, True),\n",
       " ({'word': 'monocytogenes'}, True),\n",
       " ({'word': 'January'}, True),\n",
       " ({'word': 'WHO'}, True),\n",
       " ({'word': '(19'}, True),\n",
       " ({'word': 'cases'}, True),\n",
       " ({'word': 'rockmelons'}, True),\n",
       " ({'word': 'National'}, False),\n",
       " ({'word': '2018,'}, False),\n",
       " ({'word': 'Listeria'}, False),\n",
       " ({'word': 'listeriosis'}, False),\n",
       " ({'word': 'associated'}, False),\n",
       " ({'word': 'confirmed'}, False),\n",
       " ({'word': 'reported.'}, False),\n",
       " ({'word': '(NFP)'}, False),\n",
       " ({'word': '6'}, False),\n",
       " ({'word': 'news9'}, False),\n",
       " ({'word': '20'}, False),\n",
       " ({'word': 'March'}, False),\n",
       " ({'word': 'Australian'}, False),\n",
       " ({'word': '2'}, False),\n",
       " ({'word': 'Focal'}, False),\n",
       " ({'word': 'Disease'}, False),\n",
       " ({'word': '17'}, False),\n",
       " ({'word': '2018'}, False),\n",
       " ({'word': 'infection'}, False),\n",
       " ({'word': 'grower.From'}, False),\n",
       " ({'word': '1'}, False),\n",
       " ({'word': 'outbreak'}, False),\n",
       " ({'word': 'probable)'}, False),\n",
       " ({'word': '(cantaloupe)'}, False),\n",
       " ({'word': 'notified'}, False),\n",
       " ({'word': 'April'}, False),\n",
       " ({'word': '(listeriosis)'}, False),\n",
       " ({'word': 'consumption'}, False),\n",
       " ({'word': 'single'}, False),\n",
       " ({'word': 'Point'}, False),\n",
       " ({'word': '2018On'}, False),\n",
       " ({'word': 'monocytogenes'}, False),\n",
       " ({'word': 'January'}, False),\n",
       " ({'word': 'WHO'}, False),\n",
       " ({'word': '(19'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': 'rockmelons'}, False),\n",
       " ({'word': 'National'}, False),\n",
       " ({'word': '2018,'}, False),\n",
       " ({'word': 'Listeria'}, False),\n",
       " ({'word': 'listeriosis'}, False),\n",
       " ({'word': 'associated'}, False),\n",
       " ({'word': 'confirmed'}, False),\n",
       " ({'word': 'reported.'}, False),\n",
       " ({'word': '(NFP)'}, False),\n",
       " ({'word': '6'}, False),\n",
       " ({'word': 'news9'}, False),\n",
       " ({'word': '20'}, False),\n",
       " ({'word': 'March'}, False),\n",
       " ({'word': 'Australian'}, False),\n",
       " ({'word': '2'}, False),\n",
       " ({'word': 'Focal'}, False),\n",
       " ({'word': 'Disease'}, False),\n",
       " ({'word': '17'}, False),\n",
       " ({'word': '2018'}, False),\n",
       " ({'word': 'infection'}, False),\n",
       " ({'word': 'grower.From'}, False),\n",
       " ({'word': '1'}, False),\n",
       " ({'word': 'outbreak'}, False),\n",
       " ({'word': 'probable)'}, False),\n",
       " ({'word': '(cantaloupe)'}, False),\n",
       " ({'word': 'notified'}, False),\n",
       " ({'word': 'April'}, False),\n",
       " ({'word': '(listeriosis)'}, False),\n",
       " ({'word': 'consumption'}, False),\n",
       " ({'word': 'single'}, False),\n",
       " ({'word': 'Point'}, False),\n",
       " ({'word': '2018On'}, False),\n",
       " ({'word': 'monocytogenes'}, False),\n",
       " ({'word': 'January'}, False),\n",
       " ({'word': 'WHO'}, False),\n",
       " ({'word': '(19'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': 'rockmelons'}, False),\n",
       " ({'word': 'All'}, False),\n",
       " ({'word': 'deaths'}, False),\n",
       " ({'word': 'miscarriage'}, False),\n",
       " ({'word': 'one'}, False),\n",
       " ({'word': 'seven'}, False),\n",
       " ({'word': 'associated'}, False),\n",
       " ({'word': 'hospitalized'}, False),\n",
       " ({'word': 'outbreak.'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': 'All'}, False),\n",
       " ({'word': 'deaths'}, False),\n",
       " ({'word': 'miscarriage'}, False),\n",
       " ({'word': 'one'}, False),\n",
       " ({'word': 'seven'}, False),\n",
       " ({'word': 'associated'}, False),\n",
       " ({'word': 'hospitalized'}, False),\n",
       " ({'word': 'outbreak.'}, False),\n",
       " ({'word': 'cases'}, False),\n",
       " ({'word': '2018,'}, False),\n",
       " ({'word': 'grower'}, False),\n",
       " ({'word': 'distribution'}, False),\n",
       " ({'word': 'led'}, False),\n",
       " ({'word': 'environmental'}, False),\n",
       " ({'word': 'international'}, False),\n",
       " ({'word': 'investigations'}, False),\n",
       " ({'word': 'occurred.'}, False),\n",
       " ({'word': 'March'}, False),\n",
       " ({'word': 'Australian'}, False),\n",
       " ({'word': 'Epidemiological'}, False),\n",
       " ({'word': '27'}, False),\n",
       " ({'word': 'affected'}, False),\n",
       " ({'word': 'produced'}, False),\n",
       " ({'word': 'February'}, False),\n",
       " ({'word': 'recall'}, False),\n",
       " ({'word': '2018.On'}, False),\n",
       " ({'word': 'product'}, False),\n",
       " ({'word': '1'}, False),\n",
       " ({'word': 'NFP'}, False),\n",
       " ({'word': 'notified'}, False),\n",
       " ({'word': 'single'}, False),\n",
       " ({'word': 'rockmelons'}, False),\n",
       " ({'word': 'undertaken,'}, False),\n",
       " ({'word': 'Arab'}, False),\n",
       " ({'word': 'United'}, False),\n",
       " ({'word': 'grower'}, False),\n",
       " ({'word': '(China),'}, False),\n",
       " ({'word': 'Hong'}, False),\n",
       " ({'word': 'Kong'}, False),\n",
       " ({'word': 'investigations'}, False),\n",
       " ({'word': 'Oman,'}, False),\n",
       " ({'word': 'countries;'}, False),\n",
       " ({'word': 'Region'}, False),\n",
       " ({'word': 'eight'}, False),\n",
       " ({'word': 'Administrative'}, False),\n",
       " ({'word': 'Australian'}, False),\n",
       " ({'word': 'March'}, False),\n",
       " ({'word': '2'}, False),\n",
       " ({'word': 'Emirates.'}, False),\n",
       " ({'word': 'received'}, False),\n",
       " ({'word': 'forward'}, False),\n",
       " ({'word': 'information'}, False),\n",
       " ({'word': '2018'}, False),\n",
       " ({'word': 'Qatar,'}, False),\n",
       " ({'word': 'Special'}, False),\n",
       " ({'word': 'Japan,'}, False),\n",
       " ({'word': 'Kuwait,'}, False),\n",
       " ({'word': 'Singapore,'}, False),\n",
       " ({'word': 'trace'}, False),\n",
       " ({'word': 'Malaysia,'}, False),\n",
       " ({'word': 'authorities'}, False),\n",
       " ({'word': 'rockmelons'}, False),\n",
       " ({'word': 'exported'}, False),\n",
       " ({'word': 'became'}, False),\n",
       " ({'word': '2018,'}, False),\n",
       " ({'word': 'Listeria'}, False),\n",
       " ({'word': 'reported'}, False),\n",
       " ({'word': 'INFOSAN'}, False),\n",
       " ({'word': 'grower'}, False),\n",
       " ({'word': 'distribution'}, False),\n",
       " ({'word': 'melons'}, False),\n",
       " ({'word': 'contact'}, False),\n",
       " ({'word': 'positive'}, False),\n",
       " ...]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "as_tuples = df_sent.apply(tuple, axis=1).tolist()\n",
    "as_tuples = [({'word':word}, label) for label, word in as_tuples]\n",
    "as_tuples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    word = 'variant'        True : False  =     31.1 : 1.0\n",
      "                    word = 'poultry'        True : False  =     27.1 : 1.0\n",
      "                    word = 'Laibin'         True : False  =     22.2 : 1.0\n",
      "                    word = '42-year-old'    True : False  =     22.2 : 1.0\n",
      "                    word = 'strains.'       True : False  =     19.2 : 1.0\n",
      "                    word = '13For'          True : False  =     19.2 : 1.0\n",
      "                    word = 'H1N2'           True : False  =     19.2 : 1.0\n",
      "                    word = 'straight'       True : False  =     19.2 : 1.0\n",
      "                    word = 'provinces.Aug'   True : False  =     19.2 : 1.0\n",
      "                    word = 'Ohio.The'       True : False  =     19.2 : 1.0\n",
      "                    word = 'fair,'          True : False  =     19.2 : 1.0\n",
      "                    word = '(H1N2v)'        True : False  =     19.2 : 1.0\n",
      "                    word = 'desert'         True : False  =     17.3 : 1.0\n",
      "                    word = 'vaccination.'   True : False  =     17.3 : 1.0\n",
      "                    word = 'China,'         True : False  =     17.3 : 1.0\n",
      "                    word = 'Bulgaria,'      True : False  =     17.3 : 1.0\n",
      "                    word = 'squirrels'      True : False  =     17.3 : 1.0\n",
      "                    word = 'media'          True : False  =     16.3 : 1.0\n",
      "                    word = 'Guangxi'        True : False  =     16.3 : 1.0\n",
      "                    word = 'lived'          True : False  =     15.9 : 1.0\n"
     ]
    }
   ],
   "source": [
    "clf = nltk.NaiveBayesClassifier.train(as_tuples)\n",
    "clf.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sent_date = ExtractSentencesAndLabel('dates').data_output()\n",
    "df_sent_date['sentence']= df_sent_date['sentence'].apply(lambda x: list(set(x.split()) - set(stopwords.words('english'))))\n",
    "df_sent_date = split_list_and_distribute_to_new_rows(df_sent_date, 'sentence')\n",
    "as_tuples_date = df_sent_date.apply(tuple, axis=1).tolist()\n",
    "as_tuples_date = [({'sent':word}, label) for label, word in as_tuples_date]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    sent = 'worm'           True : False  =      6.0 : 1.0\n",
      "                    sent = 'occurring'      True : False  =      5.3 : 1.0\n",
      "                    sent = 'Northern'       True : False  =      5.3 : 1.0\n",
      "                    sent = 'emerging'       True : False  =      5.3 : 1.0\n",
      "                    sent = 'patients'      False : True   =      4.5 : 1.0\n",
      "                    sent = 'South'          True : False  =      4.1 : 1.0\n",
      "                    sent = 'deaths'        False : True   =      3.9 : 1.0\n",
      "                    sent = 'responseJoint'   True : False  =      3.8 : 1.0\n",
      "                    sent = '—'              True : False  =      3.8 : 1.0\n",
      "                    sent = '24,'            True : False  =      3.8 : 1.0\n",
      "                    sent = 'Ireland'        True : False  =      3.8 : 1.0\n",
      "                    sent = 'Referral'       True : False  =      3.8 : 1.0\n",
      "                    sent = 'Kingdom'        True : False  =      3.8 : 1.0\n",
      "                    sent = 'evidence'       True : False  =      3.8 : 1.0\n",
      "                    sent = 'This'           True : False  =      3.8 : 1.0\n",
      "                    sent = 'Great'          True : False  =      3.8 : 1.0\n",
      "                    sent = 'lifelong'       True : False  =      3.8 : 1.0\n",
      "                    sent = 'protected'      True : False  =      3.8 : 1.0\n",
      "                    sent = 'OPV'            True : False  =      3.8 : 1.0\n",
      "                    sent = 'Syria'          True : False  =      3.8 : 1.0\n"
     ]
    }
   ],
   "source": [
    "clf_date = nltk.NaiveBayesClassifier.train(as_tuples_date)\n",
    "clf_date.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recommendation Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_recommand = RecommenderLabeling().data_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tiers = RecommenderTierAnnotation().data_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>counts</th>\n",
       "      <th>date</th>\n",
       "      <th>diseases</th>\n",
       "      <th>geoname</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[357, 60]</td>\n",
       "      <td>[[2018-12-06 00:00:00, 2018-12-27 00:00:00], [...</td>\n",
       "      <td>Ebola hemorrhagic fever</td>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>False</td>\n",
       "      <td>Ebola virus disease – Democratic Republic of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[1]</td>\n",
       "      <td>[[2018-10-31 00:00:00, 2018-12-01 00:00:00]]</td>\n",
       "      <td>None</td>\n",
       "      <td>Kingdom of Saudi Arabia</td>\n",
       "      <td>False</td>\n",
       "      <td>Middle East respiratory syndrome coronavirus (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[6, 1, 5]</td>\n",
       "      <td>[[2016-01-01 00:00:00, 2019-01-01 00:00:00]]</td>\n",
       "      <td>typhoid fever</td>\n",
       "      <td>Islamic Republic of Pakistan</td>\n",
       "      <td>False</td>\n",
       "      <td>Typhoid fever – Islamic Republic of PakistanDi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[18]</td>\n",
       "      <td>[[2018-08-01 00:00:00, 2018-09-01 00:00:00]]</td>\n",
       "      <td>Ebola hemorrhagic fever</td>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>False</td>\n",
       "      <td>Ebola virus disease – Democratic Republic of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[[2018-11-18 00:00:00, 2018-11-19 00:00:00]]</td>\n",
       "      <td>yellow fever</td>\n",
       "      <td>Gambia</td>\n",
       "      <td>False</td>\n",
       "      <td>Yellow Fever – Kingdom of the NetherlandsDisea...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      counts                                               date  \\\n",
       "0  [357, 60]  [[2018-12-06 00:00:00, 2018-12-27 00:00:00], [...   \n",
       "1        [1]       [[2018-10-31 00:00:00, 2018-12-01 00:00:00]]   \n",
       "2  [6, 1, 5]       [[2016-01-01 00:00:00, 2019-01-01 00:00:00]]   \n",
       "3       [18]       [[2018-08-01 00:00:00, 2018-09-01 00:00:00]]   \n",
       "4     [1, 1]       [[2018-11-18 00:00:00, 2018-11-19 00:00:00]]   \n",
       "\n",
       "                  diseases                           geoname  label  \\\n",
       "0  Ebola hemorrhagic fever  Democratic Republic of the Congo  False   \n",
       "1                     None           Kingdom of Saudi Arabia  False   \n",
       "2            typhoid fever      Islamic Republic of Pakistan  False   \n",
       "3  Ebola hemorrhagic fever  Democratic Republic of the Congo  False   \n",
       "4             yellow fever                            Gambia  False   \n",
       "\n",
       "                                                text  \n",
       "0  Ebola virus disease – Democratic Republic of t...  \n",
       "1  Middle East respiratory syndrome coronavirus (...  \n",
       "2  Typhoid fever – Islamic Republic of PakistanDi...  \n",
       "3  Ebola virus disease – Democratic Republic of t...  \n",
       "4  Yellow Fever – Kingdom of the NetherlandsDisea...  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tiers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = pd.concat([df_recommand, df_tiers],axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clf = df_clf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>extracted_text</th>\n",
       "      <th>label</th>\n",
       "      <th>counts</th>\n",
       "      <th>date</th>\n",
       "      <th>diseases</th>\n",
       "      <th>geoname</th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ebola virus disease – Democratic Republic of t...</td>\n",
       "      <td>False</td>\n",
       "      <td>[357, 60]</td>\n",
       "      <td>[[2018-12-06 00:00:00, 2018-12-27 00:00:00], [...</td>\n",
       "      <td>Ebola hemorrhagic fever</td>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>False</td>\n",
       "      <td>Ebola virus disease – Democratic Republic of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Typhoid fever – Islamic Republic of PakistanDi...</td>\n",
       "      <td>False</td>\n",
       "      <td>[6, 1, 5]</td>\n",
       "      <td>[[2016-01-01 00:00:00, 2019-01-01 00:00:00]]</td>\n",
       "      <td>typhoid fever</td>\n",
       "      <td>Islamic Republic of Pakistan</td>\n",
       "      <td>False</td>\n",
       "      <td>Typhoid fever – Islamic Republic of PakistanDi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ebola virus disease – Democratic Republic of t...</td>\n",
       "      <td>False</td>\n",
       "      <td>[18]</td>\n",
       "      <td>[[2018-08-01 00:00:00, 2018-09-01 00:00:00]]</td>\n",
       "      <td>Ebola hemorrhagic fever</td>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>False</td>\n",
       "      <td>Ebola virus disease – Democratic Republic of t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yellow Fever – Kingdom of the NetherlandsDisea...</td>\n",
       "      <td>False</td>\n",
       "      <td>[1, 1]</td>\n",
       "      <td>[[2018-11-18 00:00:00, 2018-11-19 00:00:00]]</td>\n",
       "      <td>yellow fever</td>\n",
       "      <td>Gambia</td>\n",
       "      <td>False</td>\n",
       "      <td>Yellow Fever – Kingdom of the NetherlandsDisea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Ebola virus disease – Democratic Republic of t...</td>\n",
       "      <td>False</td>\n",
       "      <td>[51, 49, 2, 17]</td>\n",
       "      <td>[[2018-10-01 00:00:00, 2018-11-01 00:00:00]]</td>\n",
       "      <td>Ebola hemorrhagic fever</td>\n",
       "      <td>Democratic Republic of the Congo</td>\n",
       "      <td>False</td>\n",
       "      <td>Ebola virus disease – Democratic Republic of t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      extracted_text  label           counts  \\\n",
       "0  Ebola virus disease – Democratic Republic of t...  False        [357, 60]   \n",
       "2  Typhoid fever – Islamic Republic of PakistanDi...  False        [6, 1, 5]   \n",
       "3  Ebola virus disease – Democratic Republic of t...  False             [18]   \n",
       "4  Yellow Fever – Kingdom of the NetherlandsDisea...  False           [1, 1]   \n",
       "5  Ebola virus disease – Democratic Republic of t...  False  [51, 49, 2, 17]   \n",
       "\n",
       "                                                date                 diseases  \\\n",
       "0  [[2018-12-06 00:00:00, 2018-12-27 00:00:00], [...  Ebola hemorrhagic fever   \n",
       "2       [[2016-01-01 00:00:00, 2019-01-01 00:00:00]]            typhoid fever   \n",
       "3       [[2018-08-01 00:00:00, 2018-09-01 00:00:00]]  Ebola hemorrhagic fever   \n",
       "4       [[2018-11-18 00:00:00, 2018-11-19 00:00:00]]             yellow fever   \n",
       "5       [[2018-10-01 00:00:00, 2018-11-01 00:00:00]]  Ebola hemorrhagic fever   \n",
       "\n",
       "                            geoname  label  \\\n",
       "0  Democratic Republic of the Congo  False   \n",
       "2      Islamic Republic of Pakistan  False   \n",
       "3  Democratic Republic of the Congo  False   \n",
       "4                            Gambia  False   \n",
       "5  Democratic Republic of the Congo  False   \n",
       "\n",
       "                                                text  \n",
       "0  Ebola virus disease – Democratic Republic of t...  \n",
       "2  Typhoid fever – Islamic Republic of PakistanDi...  \n",
       "3  Ebola virus disease – Democratic Republic of t...  \n",
       "4  Yellow Fever – Kingdom of the NetherlandsDisea...  \n",
       "5  Ebola virus disease – Democratic Republic of t...  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(lambda x: operator.contains(*x), product)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_clf['counts'] = df_clf['counts'].apply(lambda x: list(set(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_str = inflect.engine()\n",
    "num_to_str."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_to_str = inflect.engine()\n",
    "df_clf['counts'] = df_clf['counts'].apply(int(np.nanmean)).apply(lambda x: num_to_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shape (4202,) (2101,)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-78b4941bcb5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf_clf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_list_and_distribute_to_new_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_clf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'counts'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/github/nlp-surveillance/utils/my_utils.py\u001b[0m in \u001b[0;36msplit_list_and_distribute_to_new_rows\u001b[0;34m(df, split_column)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_list_and_distribute_to_new_rows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     \u001b[0mrepeated_entries_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_repeat_entries_as_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0msplit_column\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# np.concatenate does not work with tuples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/nlp-surveillance/utils/my_utils.py\u001b[0m in \u001b[0;36m_repeat_entries_as_dict\u001b[0;34m(df, length, split_column)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_repeat_entries_as_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m     repeated_entries_as_dict = {column: np.repeat(df[column].values, length) for column in df.columns\n\u001b[0m\u001b[1;32m     77\u001b[0m                                 if column != split_column}\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepeated_entries_as_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/github/nlp-surveillance/utils/my_utils.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_repeat_entries_as_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlength\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplit_column\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     repeated_entries_as_dict = {column: np.repeat(df[column].values, length) for column in df.columns\n\u001b[0;32m---> 77\u001b[0;31m                                 if column != split_column}\n\u001b[0m\u001b[1;32m     78\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrepeated_entries_as_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rki/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36mrepeat\u001b[0;34m(a, repeats, axis)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \"\"\"\n\u001b[0;32m--> 471\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'repeat'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrepeats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/rki/lib/python3.7/site-packages/numpy/core/fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[0;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shape (4202,) (2101,)"
     ]
    }
   ],
   "source": [
    "df_clf = split_list_and_distribute_to_new_rows(df_clf, 'counts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "to_train_d['features'] = to_train_d[['geoname', 'diseases', 'counts']].values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = RecommenderLabeling().data_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['annotated'] = df['annotated'].apply(lambda x: x.text)\n",
    "df['annotated'] = df['annotated'].apply(lambda x: set(x.split()) - set(sw))\n",
    "df['annotated'] = df['annotated'].apply(lambda x: ' '.join(list(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Oversample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe1 = make_pipeline_imb(TfidfVectorizer(),\n",
    "                         ADASYN(),\n",
    "                         MultinomialNB())\n",
    "pipe2 = make_pipeline_imb(TfidfVectorizer(),\n",
    "                         ADASYN(),\n",
    "                         MultinomialNB())\n",
    "pipe3 = make_pipeline_imb(TfidfVectorizer(),\n",
    "                         MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count = to_train_d['counts'].replace(-np.inf, 0.).apply(int).apply(lambda x: p.number_to_words(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train_d['features'] = to_train_d['features'].apply(lambda x: ' '.join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = \\\n",
    "    ms.train_test_split(df['annotated'], df['label'], test_size=.2)\n",
    "y_balanced = compute_sample_weight(class_weight='balanced', y=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipe1.fit(X_train, y_train)\n",
    "# pipe2.fit(X_train, y_train)\n",
    "pipe3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_train)\n",
    "y_pred = pipe.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_pred, y_train))  #  TEXT WITHOUT STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  #  TEXT WITHOUT STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  #  TEXT WITHOUT STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  # RAW TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  # COMBINED"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  # DISEASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  # GEONAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  # COUNT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_balanced = y_balanced/min(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_balanced = [int(np.ceil(i)) for i in y_balanced]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = [int(np.ceil(i)) for i in y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(y_balanced)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe.fit(X_train, y_balanced)\n",
    "y_pred = pipe.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report_imbalanced(y_test, y_pred))  #  weighted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = text.TfidfVectorizer()\n",
    "X = tf.fit_transform(to_train_d['geoname'])\n",
    "y = to_train_d['label'].apply(int)\n",
    "y_balanced = compute_sample_weight(class_weight='balanced', y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 100 * X.nnz / float(X.shape[0] * X.shape[1])\n",
    "print(f\"Each sample has ~{p:.2f}% non-zero features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = \\\n",
    "    ms.train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb = ms.GridSearchCV(\n",
    "    nb.BernoulliNB(),\n",
    "    param_grid={'alpha': np.logspace(-2., 2., 50)})\n",
    "bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnb.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We first get the words corresponding to each feature\n",
    "names = np.asarray(tf.get_feature_names())\n",
    "# Next, we display the 50 words with the largest\n",
    "# coefficients.\n",
    "print(','.join(names[np.argsort(\n",
    "    bnb.best_estimator_.coef_[0, :])[::-1][:50]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# STUFF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from epitator.annotator import AnnoDoc\n",
    "from epitator.geoname_annotator import GeonameAnnotator\n",
    "from epitator.resolved_keyword_annotator import ResolvedKeywordAnnotator\n",
    "from epitator.count_annotator import CountAnnotator\n",
    "from epitator.date_annotator import DateAnnotator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_surveillance.pipeline import ScrapeFromURLsAndExtractText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ScrapeFromURLsAndExtractText('promed').data_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()['extracted_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_hdf('delete.hdf', key='df', format='table')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask.dataframe as dd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd1 = dd.read_hdf('delete.hdf', key='df')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2 = dd1['extracted_text'].apply(lambda x: AnnoDoc(x).add_tiers(CountAnnotator()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd2.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.pipeline import make_pipeline as make_pipeline_imb\n",
    "from imblearn.metrics import classification_report_imbalanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "categories = ['alt.atheism', 'talk.religion.misc',\n",
    "              'comp.graphics', 'sci.space']\n",
    "newsgroups_train = fetch_20newsgroups(subset='train',\n",
    "                                      categories=categories)\n",
    "newsgroups_test = fetch_20newsgroups(subset='test',\n",
    "                                     categories=categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE, ADASYN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_surveillance.pipeline import ScrapeFromURLsAndExtractText\n",
    "ScrapeFromURLsAndExtractText('who').data_output().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_surveillance.pipeline import RecommenderTierAnnotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MeanEmbeddingTransformer(TransformerMixin):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self._vocab, self._E = self._load_words()\n",
    "        \n",
    "    \n",
    "    def _load_words(self):\n",
    "        E = {}\n",
    "        vocab = []\n",
    "\n",
    "        with open('nlp_surveillance/glove.6B.50d.txt', 'r', encoding=\"utf8\") as file:\n",
    "            for i, line in enumerate(file):\n",
    "                l = line.split(' ')\n",
    "                if l[0].isalpha():\n",
    "                    v = [float(i) for i in l[1:]]\n",
    "                    E[l[0]] = np.array(v)\n",
    "                    vocab.append(l[0])\n",
    "        return np.array(vocab), E            \n",
    "\n",
    "    \n",
    "    def _get_word(self, v):\n",
    "        for i, emb in enumerate(self._E):\n",
    "            if np.array_equal(emb, v):\n",
    "                return self._vocab[i]\n",
    "        return None\n",
    "    \n",
    "    def _doc_mean(self, doc):\n",
    "        return np.mean(np.array([self._E[w.lower().strip()] for w in doc if w.lower().strip() in self._E]), axis=0)\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        return np.array([self._doc_mean(doc) for doc in X])\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X).transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc(clf, X_test, y_test):\n",
    "    y_pred = clf.predict(X_test)\n",
    "    fpr, tpr, _ = roc_curve(y_test, y_pred)\n",
    "    plt.plot(fpr, tpr)\n",
    "    plt.xlabel('FPR')\n",
    "    plt.ylabel('TPR')\n",
    "    \n",
    "def print_scores(clf, X_train, y_train, X_test, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred = clf.predict(X_test)\n",
    "    print(classification.accuracy_score(y_pred,y_test))\n",
    "    print(confusion_matrix(y_pred,y_test))\n",
    "    print('F1 score: {:3f}'.format(f1_score(y_test, y_pred)))\n",
    "    print('AUC score: {:3f}'.format(roc_auc_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('data/recommender/with_label.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.memory_usage(deep=True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['extracted_text'].values\n",
    "y = df['label'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_transform(X, sample_size):\n",
    "    essays1 = X\n",
    "    tok_es1 = [word_tokenize(doc) for doc in essays1[:sample_size]]\n",
    "    met = MeanEmbeddingTransformer()\n",
    "    X_transform = met.fit_transform(tok_es1)\n",
    "    return X_transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = tokenize_and_transform(X, 3200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('X_embed.csv', X_transform, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform = np.loadtxt('X_embed.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X_resample,\n",
    "#                                                     y_resample, stratify=y_resample, random_state=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_transform,\n",
    "                                                    y[:3200], random_state=0)\n",
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resample, y_resample = rus.fit_sample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomOverSampler(random_state=0)\n",
    "X_resample, y_resample = rus.fit_sample(X_transform, y[:X_transform.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "print_scores(lr, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(lr, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier()\n",
    "print_scores(knn, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(knn, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier().fit(X_resample, y_resample)\n",
    "print_scores(rf, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(rf, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = SVC().fit(X_resample, y_resample)\n",
    "print_scores(svc, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svc = LinearSVC().fit(X_resample, y_resample)\n",
    "print_scores(svc, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(svc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc = DecisionTreeClassifier().fit(X_resample, y_resample)\n",
    "y_pred = dtc.predict(X_test)\n",
    "print_scores(dtc, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(dtc, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier().fit(X_resample, y_resample)\n",
    "print_scores(mlp, X_resample, y_resample, X_test, y_test)\n",
    "plot_roc(mlp, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(LogisticRegression(), \n",
    "             param_grid={'C': [0.0001, 0.001, 0.01, 0.1, 1]}, scoring=\"roc_auc\", cv=4)\n",
    "gs = gs.fit(X_resample, y_resample)\n",
    "print(gs.best_params_)\n",
    "print('best score: {:3f}'.format(gs.best_score_))\n",
    "plot_roc(gs, X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C': [0.001, 0.01, 0.1, 1, 10]}\n",
    "gs = GridSearchCV(LinearSVC(), \n",
    "             param_grid=param_grid, scoring=\"roc_auc\", cv=4)\n",
    "gs = gs.fit(X_resample, y_resample)\n",
    "print(gs.best_params_)\n",
    "print('best score: {:3f}'.format(gs.best_score_))\n",
    "plot_roc(gs, X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'activation': ['relu', 'logistic', 'tanh'],\n",
    "              'alpha': [0.0001, 0.001, 0.01],\n",
    "              'learning_rate': ['constant', 'invscaling', 'adaptive'], 'tol': [0.01]}\n",
    "gs = GridSearchCV(MLPClassifier(), \n",
    "             param_grid=param_grid, scoring=\"roc_auc\", cv=4)\n",
    "gs = gs.fit(X_transform, y[:3200])\n",
    "print(gs.best_params_)\n",
    "print('best score: {:3f}'.format(gs.best_score_))\n",
    "plot_roc(gs, X_resample, y_resample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform_cluster = KMeans(n_clusters=5).fit_transform(X_transform, y[:3200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resample_cluster, y_resample_cluster = rus.fit_sample(X_transform_cluster, y[:X_transform_cluster.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cluster, X_test_cluster, y_train_cluster, y_test_cluster = train_test_split(X_resample_cluster,\n",
    "                                                    y_resample_cluster, stratify=y_resample_cluster, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "print_scores(lr, X_train_cluster, y_train_cluster, X_test_cluster, y_test_cluster)\n",
    "plot_roc(lr, X_test_cluster, y_test_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_transform_pca = PCA().fit_transform(X_transform, y[:3200])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rus = RandomUnderSampler(random_state=0)\n",
    "X_resample_pca, y_resample_pca = rus.fit_sample(X_transform_pca, y[:X_transform_pca.shape[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_cluster, X_test_cluster, y_train_cluster, y_test_cluster = train_test_split(X_resample_cluster,\n",
    "                                                    y_resample_cluster, stratify=y_resample_cluster, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lr = LogisticRegression()\n",
    "print_scores(lr, X_train_cluster, y_train_cluster, X_test_cluster, y_test_cluster)\n",
    "plot_roc(lr, X_test_cluster, y_test_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(X_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.shape(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_sne = 3200\n",
    "time_start = time.time()\n",
    "tsne = TSNE(n_components=2, verbose=1, perplexity=10, n_iter=500)\n",
    "tsne_results = tsne.fit_transform(X_transform)\n",
    "print('t-SNE done! Time elapsed: {} seconds'.format(time.time()-time_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_tsne = pd.DataFrame(tsne_results, columns=['x', 'y'])\n",
    "df_tsne['labels'] = y[:3200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotnine import *\n",
    "theme_set(theme_bw())\n",
    "(ggplot(df_tsne, aes(x='x', y='y', color='labels')) \n",
    " + geom_point()\n",
    " + xlab(\"t-SNE-x\") + ylab(\"t-SNE-y\") + ggtitle(\"doc embedding t-SNE\")\n",
    " + scale_color_manual(labels = (True, False), values = (\"pink\", \"purple\"))\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_surveillance.scraper import who_scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "who_scraper.scrape()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
