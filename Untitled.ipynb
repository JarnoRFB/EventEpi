{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_surveillance.pipeline import ExtractSentencesAndLabel\n",
    "from nlp_surveillance.classifier import summarize\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nlp_surveillance.classifier import extract_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = ExtractSentencesAndLabel('counts').data_output()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sentence']= df['sentence'].apply(lambda x: list(set(x.split()) - set(stopwords.words('english'))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = extract_sentence.split_list_and_distribute_to_new_rows(df, 'sentence')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "as_tuples = df.apply(tuple, axis=1).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "as_tuples = [({'sent':two}, one) for one,two in as_tuples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gender_features(word):\n",
    "    return {'last_letter': word[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_names = ([(name, 'male') for name in names.words('male.txt')]+([(name, 'female') for name in names.words('female.txt')]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random \n",
    "random.shuffle(labeled_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "featuresets = [(gender_features(n), gender) for (n,gender) in labeled_names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = nltk.NaiveBayesClassifier.train(as_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'male'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.classify({'last_letter': 'n'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.77"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.classify.accuracy(clf,featuresets[:500] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    sent = 'since'          True : False  =      8.4 : 1.0\n",
      "                    sent = 'public'         True : False  =      7.1 : 1.0\n",
      "                    sent = 'include'        True : False  =      5.8 : 1.0\n",
      "                    sent = 'worm'           True : False  =      5.0 : 1.0\n",
      "                    sent = 'first'         False : True   =      5.0 : 1.0\n",
      "                    sent = 'emerging'       True : False  =      4.5 : 1.0\n",
      "                    sent = 'medical'        True : False  =      4.5 : 1.0\n",
      "                    sent = 'Northern'       True : False  =      4.5 : 1.0\n",
      "                    sent = 'dengue'        False : True   =      4.3 : 1.0\n",
      "                    sent = 'countries'     False : True   =      4.3 : 1.0\n",
      "                    sent = 'Sep'           False : True   =      4.0 : 1.0\n",
      "                    sent = '8'             False : True   =      3.6 : 1.0\n",
      "                    sent = 'statement'      True : False  =      3.5 : 1.0\n",
      "                    sent = 'Lassa'          True : False  =      3.5 : 1.0\n",
      "                    sent = 'South'          True : False  =      3.5 : 1.0\n",
      "                    sent = 'surveillance'  False : True   =      3.3 : 1.0\n",
      "                    sent = 'funding'        True : False  =      3.2 : 1.0\n",
      "                    sent = '\"In'            True : False  =      3.2 : 1.0\n",
      "                    sent = 'TB'             True : False  =      3.2 : 1.0\n",
      "                    sent = 'press'          True : False  =      3.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Dates\n",
    "clf.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                    sent = 'poultry'        True : False  =     26.8 : 1.0\n",
      "                    sent = 'Delaware'       True : False  =     24.8 : 1.0\n",
      "                    sent = 'Laibin'         True : False  =     21.9 : 1.0\n",
      "                    sent = '42-year-old'    True : False  =     21.9 : 1.0\n",
      "                    sent = 'Bulgaria,'      True : False  =     17.0 : 1.0\n",
      "                    sent = 'desert'         True : False  =     17.0 : 1.0\n",
      "                    sent = 'vomiting'       True : False  =     17.0 : 1.0\n",
      "                    sent = 'squirrels'      True : False  =     17.0 : 1.0\n",
      "                    sent = 'China,'         True : False  =     17.0 : 1.0\n",
      "                    sent = 'Guangxi'        True : False  =     16.1 : 1.0\n",
      "                    sent = 'media'          True : False  =     16.1 : 1.0\n",
      "                    sent = 'lived'          True : False  =     15.6 : 1.0\n",
      "                    sent = 'Animal'         True : False  =     13.6 : 1.0\n",
      "                    sent = 'Great'          True : False  =     13.6 : 1.0\n",
      "                    sent = 'Britain'        True : False  =     13.6 : 1.0\n",
      "                    sent = 'Northern'       True : False  =     13.6 : 1.0\n",
      "                    sent = 'Vaccination'    True : False  =     13.1 : 1.0\n",
      "                    sent = 'promptly'       True : False  =     13.1 : 1.0\n",
      "                    sent = 'Mubende'        True : False  =     12.2 : 1.0\n",
      "                    sent = '10,'            True : False  =     12.2 : 1.0\n"
     ]
    }
   ],
   "source": [
    "# Counts\n",
    "clf.show_most_informative_features(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_ = os.listdir('nlp_surveillance/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = [f'nlp_surveillance/{file}' for file in dir_ if 'batch' in file]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = []\n",
    "for batch in batches:\n",
    "    found_number = re.search(r'(\\d+)',batch)[0]\n",
    "    padded_num = found_number.zfill(4)\n",
    "    padded.append((padded_num, batch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "batches = sorted(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "first = batches[0][1]\n",
    "with open(first, 'rb') as batch_handle:\n",
    "    recommender_with_entities = pickle.load(batch_handle)\n",
    "    recommender_with_entities = [recommender_with_entities]\n",
    "for batch in batches[1:]:\n",
    "    with open(batch[1], 'rb') as batch_handle:\n",
    "        to_append = pickle.load(batch_handle)\n",
    "        recommender_with_entities.append(to_append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommender_with_entities = [pd.DataFrame(d) for d in recommender_with_entities]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatted = pd.concat(recommender_with_entities, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatted['counts'] = concatted['counts'].apply(lambda x: int(sum(x)/len(x)) if x  else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "concatted['counts'] = concatted['counts'].apply(np.log10).apply(np.round)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = concatted.drop(columns='date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nlp_surveillance.pipeline import RecommenderLabeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = RecommenderLabeling().data_output()['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train = pd.concat([to_train, label],axis=1, ignore_index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_train_d = to_train.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "import sklearn.model_selection as ms\n",
    "import sklearn.feature_extraction.text as text\n",
    "import sklearn.naive_bayes as nb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_sample_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = text.TfidfVectorizer()\n",
    "X = tf.fit_transform(to_train_d['geoname'])\n",
    "y = to_train_d['label'].apply(int)\n",
    "y_balanced = compute_sample_weight(class_weight='balanced', y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Each sample has ~1.78% non-zero features.\n"
     ]
    }
   ],
   "source": [
    "p = 100 * X.nnz / float(X.shape[0] * X.shape[1])\n",
    "print(f\"Each sample has ~{p:.2f}% non-zero features.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "(X_train, X_test, y_train, y_test) = \\\n",
    "    ms.train_test_split(X, y, test_size=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/auss/miniconda3/envs/rki/lib/python3.7/site-packages/sklearn/model_selection/_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
       "       estimator=BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True),\n",
       "       fit_params=None, iid='warn', n_jobs=None,\n",
       "       param_grid={'alpha': array([1.00000e-02, 1.20679e-02, 1.45635e-02, 1.75751e-02, 2.12095e-02,\n",
       "       2.55955e-02, 3.08884e-02, 3.72759e-02, 4.49843e-02, 5.42868e-02,\n",
       "       6.55129e-02, 7.90604e-02, 9.54095e-02, 1.15140e-01, 1.38950e-01,\n",
       "       1.67683e-01, 2.02359e-01, 2.44205e-01, 2.94705e-01, 3.55... 3.23746e+01, 3.90694e+01,\n",
       "       4.71487e+01, 5.68987e+01, 6.86649e+01, 8.28643e+01, 1.00000e+02])},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb = ms.GridSearchCV(\n",
    "    nb.BernoulliNB(),\n",
    "    param_grid={'alpha': np.logspace(-2., 2., 50)})\n",
    "bnb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9280742459396751"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bnb.score(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted = bnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.99      0.96       403\n",
      "           1       0.20      0.04      0.06        28\n",
      "\n",
      "   micro avg       0.93      0.93      0.93       431\n",
      "   macro avg       0.57      0.51      0.51       431\n",
      "weighted avg       0.89      0.93      0.90       431\n",
      "\n",
      "[[399   4]\n",
      " [ 27   1]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test, predicted))\n",
    "print(metrics.confusion_matrix(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "of,republic,united,federal,nigeria,kingdom,democratic,states,the,congo,and,ireland,northern,great,britain,state,india,kenya,uganda,liberia,commonwealth,people,australia,new,spain,islamic,papua,guinea,independent,plurinational,brazil,pakistan,burma,yemen,china,bolivia,algeria,switzerland,dominican,union,federative,czechia,zealand,afghanistan,france,lebanon,costa,peru,saudi,taiwan\n"
     ]
    }
   ],
   "source": [
    "# We first get the words corresponding to each feature\n",
    "names = np.asarray(tf.get_feature_names())\n",
    "# Next, we display the 50 words with the largest\n",
    "# coefficients.\n",
    "print(','.join(names[np.argsort(\n",
    "    bnb.best_estimator_.coef_[0, :])[::-1][:50]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
